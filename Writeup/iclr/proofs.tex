\section{Proofs}

\subsection{Proof of Proposition \ref{localdistprop}}
Cut the integral into the three cones
and use trivial bounds. 


\subsection{Proof of Theorem \ref{maintheo}}

A path from $\theta^A$ to $\theta^B$ will be constructed 
as follows:
\begin{enumerate}
\item from $\theta^A$ to $\theta_{lA}$, the 
best linear predictor using the same first layer. 
\item from $\theta_{lA}$ to $\theta_{sA}$, the best $M-n$ approximation using perturbed 
atoms, 
\item from $\theta_{sA}$ to $\theta^*$ the oracle $n$ term approximation,  
\item from $\theta^*$ to $\theta_{sB}$,
\item from $\theta_{sB}$ to $\theta_{lB}$,
\item from $\theta_{lB}$ to $\theta^{B}$.
\end{enumerate}
The subpaths (1) and (6) only involve changing the parameters of the second layer, 
which define a convex loss. Therefore a linear path is sufficient.
Subpaths (3) and (4) can also be constructed using only parameters of the second layer, 
by observing that one can fit into a single $n \times M$ parameter matrix both the 
$M-n$ term approximation and the best $n$-term approximation. A linear path is therefore 
also sufficient. 

We finally need to show how to construct the subpaths (2) and (5).
Let $\tilde{W}_A$ be the resulting perturbed first-layer parameter matrix 
with $M-n$ sparse coefficients $\gamma_A$.
Let us consider an auxiliary regression of the form 
$$\overline{W} = [ W^A ; \tilde{W}_A]$$
and regression parameters 
$$\overline{\beta}_1 = [ \beta_1; 0]~,~\overline{\beta}_2 = [0; \gamma_A]~.$$
Clearly 
$$\E\{ | Y - \overline{\beta}_1 \overline{W} |^2 \} + \kappa \| \overline{\beta}_1 \|^2 = \E\{ | Y - \beta_1 W^A |^2 \} + \kappa \| {\beta}_1 \|^2 $$ 
and similarly for $\overline{\beta}_2$. The augmented linear path $\eta(t) =(1- t) \overline{\beta}_1 + t \overline{\beta}_2$ thus satisfies 
$$\forall~t~,\overline{L}(t) = \E\{ | Y - \eta(t) \overline{W} |^2 \} + \kappa \| \eta(t) \|^2 \leq \max(\overline{L}(0), \overline{L}(1))~. $$
Let us now approximate this augmented linear path with a path in terms of first and second layer weights. 
We consider
$$\eta_1(t) = (1-t) W^A + t \tilde{W}_A~,\text{ and}~\eta_2(t) = (1- t) {\beta}_1 + t \gamma_A~.$$
We verify that 
\begin{eqnarray}
\label{bub1}
\Forr(\{ \eta_1(t), \eta_2(t) \}) &=& \E \{ | Y - \eta_2(t) Z(\eta_1(t) ) |^2 \} + \kappa \| \eta_2(t) \|^2  \nonumber \\ 
&\leq & \E \{ | Y - \eta_2(t) Z(\eta_1(t) ) |^2 \} + \kappa(  ( 1-t) \| {\beta}_1\|^2 + t \| \gamma_A \|^2 ) \nonumber \\
& = & \overline{L}(t) + \E \{ | Y - \eta_2(t) Z(\eta_1(t) ) |^2 \}  - \E \{ | Y - (1-t) \beta_1 Z(W^A) - t \gamma_A Z(\tilde{W}_A) |^2 \} ~.
\end{eqnarray}
Finally, we verify that
\begin{equation}
\label{bub2}
\left | \E \{ | Y - \eta_2(t) Z(\eta_1(t) ) |^2 \}  - \E \{ | Y - (1-t) \beta_1 Z(W^A) - t \gamma_A Z(\tilde{W}_A) |^2 \} \right| \leq 4 \max(1, \sqrt{\E|Y^2|}) \| \Sigma_X \| \alpha ( \kappa^{-1/2} + M \kappa^{-1}) + O(\alpha^2)~.
\end{equation}
From Proposition \ref{localdistprop}, and using the fact that 
$$\forall~i\leq M,\, t \in [0,1]~,~\left| \angle( (1-t)w^A_i + t \tilde{w}^A_i ; w^A_i) \right| \leq \alpha~,~ \left| \angle( (1-t)w^A_i + t \tilde{w}^A_i ; \tilde{w}^A_i) \right| \leq \alpha $$
we can write 
$$(1-t) \beta_1[i] z(w^A_i) - t \gamma_A[i] z(\tilde{w}^A_i) \stackrel{d}{=} \eta_2(t)[i] z(\eta_1(t)[i]) + n_i ~,$$
with $\E\{ |n_i |^2 \} \leq 4 |\eta_2(t)[i]|^2 \| \Sigma_X \| \alpha^2 + O(\alpha^4)~$ and $\E |n_i| \leq 2 |\eta_2(t)[i]| \alpha \sqrt{\| \Sigma_X\|}$ using concavity of the moments.
Thus 
\begin{eqnarray*}
&& \left | \E \{ | Y - \eta_2(t) Z(\eta_1(t) ) |^2 \}  - \E \{ | Y - (1-t) \beta_1 Z(W^A) - t \gamma_A Z(\tilde{W}_A) |^2 \} \right| \\
 &\leq& 2\E\{  \sum_i (Y - \eta_2(t) Z(\eta_1(t) )) n[i]  \} + \E \{ | \sum_i n[i] |^2 \} \\
 &\leq & 4\left( \sqrt{\E|Y^2|} \| \Sigma_X\| \alpha \| \eta_2 \| + \alpha^2 (\| \eta_2 \|_1)^2  \| \Sigma_X \| \right) \\
 &\leq & 4 \max(1, \sqrt{\E|Y^2|}) \| \Sigma_X \| \alpha ( \| \eta_2 \| + M \| \eta_2 \|^2) + O(\alpha^2) \\
 & \leq & 4 \max(1, \sqrt{\E|Y^2|}) \| \Sigma_X \| \alpha ( \kappa^{-1/2} + M \kappa^{-1}) + O(\alpha^2)~.
\end{eqnarray*}
 
%8 \sqrt{\E|Y^2} \} \max( \| \beta \|^2, \| \gamma_A \|^2) \alpha^2 \| \Sigma_X \| 



% and  $\| \beta \| \leq \kappa^{-1}$  $\square$.

\subsection{Proof of Corollary \ref{maincoro}}


Use pigeonhole principle to control how many directions are within an angle smaller than $\epsilon$. 





