Publication quality plots

normlength.cubics contains a plot of the averaged normalized lengths of error strings for a 1-4-4-1 fc, fc, fc, sigmoid after 1st, 2nd, 3rd layer neural network which performs regression on a particular cubic polynomial
numbeads.cubics contains a logplot of the average number of beads necessary to connect two models (keeping error below the threshold along the path) for the same model as above

normlength.quadratics same as above except for a particular quadratic
normlengths.quadratics same as above

quadratic.pathinterp.errorvis.gif contains a visualization of the errorstring which connects two of the quadratic models above.
In the animation, a new bead is added to the string on each frame of the animation
The color along the beads is representative of the error at that point on the string (blue ~ .001 loss, red ~ 1.0 loss)
The axes are the top 3 principal directions for the converged error string, so a given point on the graph is the projection of some model on the error string onto the 3 principal axes for the fully converged string.

(I decided to use the principal axes for the fully converged string because if I changed the principal axes frame-by-frame, there's some jitter in the string.)

SymmetryDisconnect1 and 2 show failed runs for trying to connect models which we can prove are actually disconnected.  These gifs are actually two different runs of the algorithm on the same pair of models.  The pair of models was generated by converged one model to fairly low error, copying it, and then permuting two of the hidden nodes (this is the 2-3-2 single relu construction).
