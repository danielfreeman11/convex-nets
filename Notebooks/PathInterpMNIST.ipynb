{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Imports and model parameters\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#Simple network: Given three integers a,b,c, [-100,100] chooses three random x-values, and evaluates\n",
    "#the quadratic function a*x^2 + b*x + c at those values.\n",
    "\n",
    "import copy\n",
    "\n",
    "alpha,hidden_dim,hidden_dim2 = (.001,4,4)\n",
    "\n",
    "thresh = .1\n",
    "\n",
    "cost_thresh = 1.0\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # Guess quadratic function\n",
    "n_classes = 10 # \n",
    "#synapses = []\n",
    "models = []\n",
    "\n",
    "#Testing starting in the same place\n",
    "#synapse0 = 2*np.random.random((1,hidden_dim)) - 1\n",
    "#synapse1 = 2*np.random.random((hidden_dim,hidden_dim2)) - 1\n",
    "#synapse2 = 2*np.random.random((hidden_dim2,1)) - 1\n",
    "copy_model = multilayer_perceptron(ind=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function definitions\n",
    "\n",
    "def func(x,a,b,c):\n",
    "    return x*x*a + x*b + c\n",
    "\n",
    "def generatecandidate4(a,b,c,tot):\n",
    "    \n",
    "    candidate = [[np.random.random() for x in xrange(1)] for y in xrange(tot)]\n",
    "    candidatesolutions = [[func(x[0],a,b,c)] for x in candidate]\n",
    "    \n",
    "    return (candidate, candidatesolutions)\n",
    "\n",
    "def synapse_interpolate(synapse1, synapse2, t):\n",
    "    return (synapse2-synapse1)*t + synapse1\n",
    "\n",
    "def model_interpolate(w1,b1,w2,b2,t):\n",
    "    \n",
    "    m1w = w1\n",
    "    m1b = b1\n",
    "    m2w = w2 \n",
    "    m2b = b2\n",
    "    \n",
    "    mwi = [synapse_interpolate(m1we,m2we,t) for m1we, m2we in zip(m1w,m2w)]\n",
    "    mbi = [synapse_interpolate(m1be,m2be,t) for m1be, m2be in zip(m1b,m2b)]\n",
    "    \n",
    "    return mwi, mbi\n",
    "\n",
    "def InterpBeadError(w1,b1, w2,b2, write = False, name = \"00\"):\n",
    "    errors = []\n",
    "    \n",
    "    #xdat,ydat = generatecandidate4(.5, .25, .1, 1000)\n",
    "    \n",
    "    xdat,ydat = mnist.train.next_batch(batch_size)\n",
    "    #xdat = np.array(xdat)\n",
    "    #ydat = np.array(ydat)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for tt in xrange(100):\n",
    "        #print tt\n",
    "        #accuracy = 0.\n",
    "        t = tt/100.\n",
    "        thiserror = 0\n",
    "\n",
    "        #x0 = tf.placeholder(\"float\", [None, n_input])\n",
    "        #y0 = tf.placeholder(\"float\", [None, n_classes])\n",
    "        weights, biases = model_interpolate(w1,b1,w2,b2, t)\n",
    "        interp_model = multilayer_perceptron(w=weights, b=biases)\n",
    "        \n",
    "        with interp_model.g.as_default():\n",
    "            \n",
    "            #interp_model.UpdateWeights(weights, biases)\n",
    "\n",
    "\n",
    "            x = tf.placeholder(\"float\", [None, n_input])\n",
    "            y = tf.placeholder(\"float\", [None, n_classes])\n",
    "            pred = interp_model.predict(x)\n",
    "            init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "                correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print \"Accuracy:\", 1 - accuracy.eval({x: xdat, y: ydat}),\"\\t\",tt,weights[0][1][0],weights[0][1][1]\n",
    "                thiserror = 1 - accuracy.eval({x: xdat, y: ydat})\n",
    "\n",
    "\n",
    "        errors.append(thiserror)\n",
    "\n",
    "    if write == True:\n",
    "        with open(\"f\" + str(name) + \".out\",'w+') as f:\n",
    "            for e in errors:\n",
    "                f.write(str(e) + \"\\n\")\n",
    "    \n",
    "    return max(errors), np.argmax(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class definitions\n",
    "\n",
    "class multilayer_perceptron():\n",
    "    \n",
    "    #weights = {}\n",
    "    #biases = {}\n",
    "    \n",
    "    def __init__(self, w=0, b=0, ind='00'):\n",
    "        \n",
    "        self.index = ind #used for reading values from file\n",
    "        #See the filesystem convention below (is this really necessary?)\n",
    "        #I'm going to eschew writing to file for now because I'll be generating too many files\n",
    "        #Currently, the last value of the parameters is stored in self.params to be read\n",
    "        \n",
    "        learning_rate = 0.001\n",
    "        training_epochs = 15\n",
    "        batch_size = 100\n",
    "        display_step = 1\n",
    "\n",
    "        # Network Parameters\n",
    "        n_hidden_1 = 256 # 1st layer number of features\n",
    "        n_hidden_2 = 256 # 2nd layer number of features\n",
    "        n_input = 784 # Guess quadratic function\n",
    "        n_classes = 10 # \n",
    "        self.g = tf.Graph()\n",
    "        \n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "        with self.g.as_default():\n",
    "        \n",
    "            #Note that by default, weights and biases will be initialized to random normal dists\n",
    "            if w==0:\n",
    "                \n",
    "                self.weights = {\n",
    "                    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "                    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "                    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "                }\n",
    "                self.weightslist = [self.weights['h1'],self.weights['h2'],self.weights['out']]\n",
    "                self.biases = {\n",
    "                    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "                    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "                    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "                }\n",
    "                self.biaseslist = [self.biases['b1'],self.biases['b2'],self.biases['out']]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                self.weights = {\n",
    "                    'h1': tf.Variable(w[0]),\n",
    "                    'h2': tf.Variable(w[1]),\n",
    "                    'out': tf.Variable(w[2])\n",
    "                }\n",
    "                self.weightslist = [self.weights['h1'],self.weights['h2'],self.weights['out']]\n",
    "                self.biases = {\n",
    "                    'b1': tf.Variable(b[0]),\n",
    "                    'b2': tf.Variable(b[1]),\n",
    "                    'out': tf.Variable(b[2])\n",
    "                }\n",
    "                self.biaseslist = [self.biases['b1'],self.biases['b2'],self.biases['out']]\n",
    "            self.saver = tf.train.Saver()\n",
    "    \n",
    "    \n",
    "    def UpdateWeights(self, w, b):\n",
    "        with self.g.as_default():\n",
    "            self.weights = {\n",
    "                    'h1': tf.Variable(w[0]),\n",
    "                    'h2': tf.Variable(w[1]),\n",
    "                    'out': tf.Variable(w[2])\n",
    "                }\n",
    "            self.weightslist = [self.weights['h1'],self.weights['h2'],self.weights['out']]\n",
    "            self.biases = {\n",
    "                'b1': tf.Variable(b[0]),\n",
    "                'b2': tf.Variable(b[1]),\n",
    "                'out': tf.Variable(b[2])\n",
    "            }\n",
    "            self.biaseslist = [self.biases['b1'],self.biases['b2'],self.biases['out']]\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \n",
    "        with self.g.as_default():\n",
    "            layer_1 = tf.add(tf.matmul(x, self.weights['h1']), self.biases['b1'])\n",
    "            layer_1 = tf.nn.relu(layer_1)\n",
    "            # Hidden layer with RELU activation\n",
    "            layer_2 = tf.add(tf.matmul(layer_1, self.weights['h2']), self.biases['b2'])\n",
    "            layer_2 = tf.nn.relu(layer_2)\n",
    "            # Output layer with linear activation\n",
    "            out_layer = tf.matmul(layer_2, self.weights['out']) + self.biases['out']\n",
    "            return out_layer\n",
    "        \n",
    "    def ReturnParamsAsList(self):\n",
    "        \n",
    "        with self.g.as_default():\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                # Restore variables from disk\n",
    "                self.saver.restore(sess, \"/home/dfreeman/PythonFun/tmp/model\"+str(self.index)+\".ckpt\")                \n",
    "                return sess.run(self.weightslist), sess.run(self.biaseslist)\n",
    "\n",
    "        \n",
    "        \n",
    "class WeightString:\n",
    "    \n",
    "    def __init__(self, w1, b1, w2, b2, numbeads, threshold):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        #self.w2, self.b2 = m2.params\n",
    "        self.AllBeads = []\n",
    "\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.AllBeads.append([w1,b1])\n",
    "        \n",
    "        \n",
    "        for n in xrange(numbeads):\n",
    "            ws,bs = model_interpolate(w1,b1,w2,b2, (n + 1.)/(numbeads+1.))\n",
    "            self.AllBeads.append([ws,bs])\n",
    "            \n",
    "        self.AllBeads.append([w2,b2])\n",
    "        \n",
    "        \n",
    "        self.ConvergedList = [False for f in xrange(len(self.AllBeads))]\n",
    "        self.ConvergedList[0] = True\n",
    "        self.ConvergedList[-1] = True\n",
    "    \n",
    "    \n",
    "    def SpringNorm(self, order):\n",
    "        \n",
    "        total = 0.\n",
    "        \n",
    "        #Energy between mobile beads\n",
    "        for i,b in enumerate(self.AllBeads):\n",
    "            if i < len(self.AllBeads)-1:\n",
    "                #print \"Tallying energy between bead \" + str(i) + \" and bead \" + str(i+1)\n",
    "                subtotal = 0.\n",
    "                for j in xrange(len(b)):\n",
    "                    subtotal += np.linalg.norm(np.subtract(self.AllBeads[i][0][j],self.AllBeads[i+1][0][j]),ord=order)#/len(self.beads[0][j])\n",
    "                for j in xrange(len(b)):\n",
    "                    subtotal += np.linalg.norm(np.subtract(self.AllBeads[i][1][j],self.AllBeads[i+1][1][j]),ord=order)#/len(self.beads[0][j])\n",
    "                total+=subtotal\n",
    "        \n",
    "        return total#/len(self.beads)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def SGDBead(self, bead, thresh, maxindex):\n",
    "        \n",
    "        finalerror = 0.\n",
    "        \n",
    "        #thresh = .05\n",
    "\n",
    "        # Parameters\n",
    "        learning_rate = 0.01\n",
    "        training_epochs = 15\n",
    "        batch_size = 1000\n",
    "        display_step = 1\n",
    "        \n",
    "        curWeights, curBiases = self.AllBeads[bead]\n",
    "        test_model = multilayer_perceptron(w=curWeights, b=curBiases)\n",
    "\n",
    "        with test_model.g.as_default():\n",
    "\n",
    "            x = tf.placeholder(\"float\", [None, n_input])\n",
    "            y = tf.placeholder(\"float\", [None, n_classes])\n",
    "            pred = test_model.predict(x)\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "            init = tf.initialize_all_variables()\n",
    "            stopcond = True\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "                xtest = mnist.test.images\n",
    "                ytest = mnist.test.labels\n",
    "                \n",
    "                thiserror = 0.\n",
    "                j = 0\n",
    "                while stopcond:\n",
    "                    for epoch in range(training_epochs):\n",
    "                        avg_cost = 0.\n",
    "                        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "                        if (avg_cost > thresh or avg_cost == 0.) and stopcond:\n",
    "                        # Loop over all batches\n",
    "                            for i in range(total_batch):\n",
    "                                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                                              y: batch_y})\n",
    "                                # Compute average loss\n",
    "                                avg_cost += c / total_batch\n",
    "                            # Display logs per epoch step\n",
    "                            #if epoch % display_step == 0:\n",
    "                            #    print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                            #        \"{:.9f}\".format(avg_cost)\n",
    "                            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                            # Calculate accuracy\n",
    "                            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                            #print \"Accuracy:\", accuracy.eval({x: xtest, y: ytest})\n",
    "                            thiserror = 1 - accuracy.eval({x: xtest, y: ytest})\n",
    "                            if thiserror < thresh:\n",
    "                                stopcond = False\n",
    "                    #print \"Optimization Finished!\"\n",
    "\n",
    "                    # Test model\n",
    "                    #correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                    #correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                    # Calculate accuracy\n",
    "                    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                    #print \"Accuracy:\", accuracy.eval({x: xtest, y: ytest})\n",
    "\n",
    "                    #if (j%5000) == 0:\n",
    "                    #    print \"Error after \"+str(j)+\" iterations:\" + str(accuracy.eval({x: xtest, y: ytest}))\n",
    "\n",
    "                    finalerror = 1 - accuracy.eval({x: xtest, y: ytest})\n",
    "                    \n",
    "                    if finalerror < thresh or stopcond==False:# or j > maxindex:\n",
    "                        #print \"Changing stopcond!\"\n",
    "                        stopcond = False\n",
    "                        #print \"Final params:\"\n",
    "                        test_model.params = sess.run(test_model.weightslist), sess.run(test_model.biaseslist)\n",
    "                        self.AllBeads[bead]=test_model.params\n",
    "                        print \"Final bead error: \" + str(finalerror)\n",
    "                        \n",
    "                    j+=1\n",
    "\n",
    "            return finalerror\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 569.200964050\n",
      "Epoch: 0002 cost= 162.350347366\n",
      "Epoch: 0003 cost= 109.549932747\n",
      "Epoch: 0004 cost= 83.252990379\n",
      "Epoch: 0005 cost= 72.425635023\n",
      "Epoch: 0006 cost= 53.994613857\n",
      "Epoch: 0007 cost= 51.823056984\n",
      "Epoch: 0008 cost= 44.821461678\n",
      "Epoch: 0009 cost= 41.322505980\n",
      "Epoch: 0010 cost= 38.339859755\n",
      "Epoch: 0011 cost= 38.245632200\n",
      "Epoch: 0012 cost= 30.248446031\n",
      "Epoch: 0013 cost= 27.927715507\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9003\n",
      "Error after 0 iterations:0.9003\n",
      "Final params:\n",
      "Epoch: 0001 cost= 462.551841125\n",
      "Epoch: 0002 cost= 138.978277740\n",
      "Epoch: 0003 cost= 100.559575577\n",
      "Epoch: 0004 cost= 74.754091358\n",
      "Epoch: 0005 cost= 62.825597267\n",
      "Epoch: 0006 cost= 54.829888697\n",
      "Epoch: 0007 cost= 49.491547890\n",
      "Epoch: 0008 cost= 44.055701201\n",
      "Epoch: 0009 cost= 41.198764448\n",
      "Epoch: 0010 cost= 33.823042288\n",
      "Epoch: 0011 cost= 32.589753995\n",
      "Epoch: 0012 cost= 28.527572842\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9028\n",
      "Error after 0 iterations:0.9028\n",
      "Final params:\n",
      "Epoch: 0001 cost= 516.627025299\n",
      "Epoch: 0002 cost= 140.971016731\n",
      "Epoch: 0003 cost= 96.274020119\n",
      "Epoch: 0004 cost= 71.887283592\n",
      "Epoch: 0005 cost= 63.750078754\n",
      "Epoch: 0006 cost= 54.013752480\n",
      "Epoch: 0007 cost= 52.205150316\n",
      "Epoch: 0008 cost= 48.441035209\n",
      "Epoch: 0009 cost= 37.454276619\n",
      "Epoch: 0010 cost= 37.021613417\n",
      "Epoch: 0011 cost= 32.234993992\n",
      "Epoch: 0012 cost= 30.552076435\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9023\n",
      "Error after 0 iterations:0.9023\n",
      "Final params:\n"
     ]
    }
   ],
   "source": [
    "#Model generation\n",
    "\n",
    "for ii in xrange(3):\n",
    "\n",
    "    '''weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }'''\n",
    "\n",
    "    # Construct model with different initial weights\n",
    "    test_model = multilayer_perceptron(ind=ii)\n",
    "    \n",
    "    #Construct model with same initial weights\n",
    "    #test_model = copy.copy(copy_model)\n",
    "    #test_model.index = ii\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print test_model.weights\n",
    "    \n",
    "\n",
    "    \n",
    "    models.append(test_model)\n",
    "    with test_model.g.as_default():\n",
    "\n",
    "        x = tf.placeholder(\"float\", [None, n_input])\n",
    "        y = tf.placeholder(\"float\", [None, n_classes])\n",
    "        pred = test_model.predict(x)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "        # Initializing the variables\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "        #remove the comment to get random initialization\n",
    "        stopcond = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            xtest = mnist.test.images\n",
    "            ytest = mnist.test.labels\n",
    "            while stopcond:\n",
    "                #print 'epoch:' + str(e)\n",
    "                #X = []\n",
    "                #y = []\n",
    "                j = 0\n",
    "                # Training cycle\n",
    "                for epoch in range(training_epochs):\n",
    "                    avg_cost = 0.\n",
    "                    total_batch = int(10000/batch_size)\n",
    "\n",
    "                    if (avg_cost > thresh or avg_cost == 0.) and stopcond:\n",
    "                    # Loop over all batches\n",
    "                        for i in range(total_batch):\n",
    "                            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                                          y: batch_y})\n",
    "                            # Compute average loss\n",
    "                            avg_cost += c / total_batch\n",
    "                        # Display logs per epoch step\n",
    "                        if epoch % display_step == 0:\n",
    "                            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                                \"{:.9f}\".format(avg_cost)\n",
    "                        \n",
    "                        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                        # Calculate accuracy\n",
    "                        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                        #print \"Accuracy:\", accuracy.eval({x: xtest, y: ytest})\n",
    "                        thiserror = 1 - accuracy.eval({x: xtest, y: ytest})\n",
    "                        if thiserror < thresh:\n",
    "                            stopcond = False\n",
    "                            \n",
    "                print \"Optimization Finished!\"\n",
    "\n",
    "                # Test model\n",
    "                #correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                # Calculate accuracy\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print \"Accuracy:\", accuracy.eval({x: xtest, y: ytest})\n",
    "\n",
    "                if (j%5000) == 0:\n",
    "                    print \"Error after \"+str(j)+\" iterations:\" + str(accuracy.eval({x: xtest, y: ytest}))\n",
    "\n",
    "                if 1 - accuracy.eval({x: xtest, y: ytest}) < thresh or stopcond == False:\n",
    "                    #print \"Changing stopcond!\"\n",
    "                    stopcond = False\n",
    "                    print \"Final params:\"\n",
    "                    test_model.params = sess.run(test_model.weightslist), sess.run(test_model.biaseslist)\n",
    "                    save_path = test_model.saver.save(sess,\"/home/dfreeman/PythonFun/tmp/model\" + str(ii) + \".ckpt\")\n",
    "                j+=1\n",
    "    #remove the comment to get random initialization\n",
    "\n",
    "    \n",
    "    #synapses.append([synapse_0,synapse_1,synapse_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0, 1]\n",
      "Final bead error: 0.0486000180244\n",
      "[True, True, True]\n",
      "Accuracy: 0.139999985695 \t0\n",
      "Accuracy: 0.139999985695 \t1\n",
      "Accuracy: 0.139999985695 \t2\n",
      "Accuracy: 0.139999985695 \t3\n",
      "Accuracy: 0.139999985695 \t4\n",
      "Accuracy: 0.139999985695 \t5\n",
      "Accuracy: 0.129999995232 \t6\n",
      "Accuracy: 0.129999995232 \t7\n",
      "Accuracy: 0.129999995232 \t8\n",
      "Accuracy: 0.129999995232 \t9\n",
      "Accuracy: 0.129999995232 \t10\n",
      "Accuracy: 0.139999985695 \t11\n",
      "Accuracy: 0.139999985695 \t12\n",
      "Accuracy: 0.149999976158 \t13\n",
      "Accuracy: 0.149999976158 \t14\n",
      "Accuracy: 0.149999976158 \t15\n",
      "Accuracy: 0.149999976158 \t16\n",
      "Accuracy: 0.149999976158 \t17\n",
      "Accuracy: 0.149999976158 \t18\n",
      "Accuracy: 0.149999976158 \t19\n",
      "Accuracy: 0.149999976158 \t20\n",
      "Accuracy: 0.149999976158 \t21\n",
      "Accuracy: 0.149999976158 \t22\n",
      "Accuracy: 0.149999976158 \t23\n",
      "Accuracy: 0.160000026226 \t24\n",
      "Accuracy: 0.160000026226 \t25\n",
      "Accuracy: 0.180000007153 \t26\n",
      "Accuracy: 0.180000007153 \t27\n",
      "Accuracy: 0.170000016689 \t28\n",
      "Accuracy: 0.180000007153 \t29\n",
      "Accuracy: 0.189999997616 \t30\n",
      "Accuracy: 0.189999997616 \t31\n",
      "Accuracy: 0.180000007153 \t32\n",
      "Accuracy: 0.180000007153 \t33\n",
      "Accuracy: 0.180000007153 \t34\n",
      "Accuracy: 0.180000007153 \t35\n",
      "Accuracy: 0.180000007153 \t36\n",
      "Accuracy: 0.180000007153 \t37\n",
      "Accuracy: 0.180000007153 \t38\n",
      "Accuracy: 0.170000016689 \t39\n",
      "Accuracy: 0.180000007153 \t40\n",
      "Accuracy: 0.180000007153 \t41\n",
      "Accuracy: 0.189999997616 \t42\n",
      "Accuracy: 0.180000007153 \t43\n",
      "Accuracy: 0.180000007153 \t44\n",
      "Accuracy: 0.180000007153 \t45\n",
      "Accuracy: 0.180000007153 \t46\n",
      "Accuracy: 0.180000007153 \t47\n",
      "Accuracy: 0.189999997616 \t48\n",
      "Accuracy: 0.189999997616 \t49\n",
      "Accuracy: 0.189999997616 \t50\n",
      "Accuracy: 0.189999997616 \t51\n",
      "Accuracy: 0.189999997616 \t52\n",
      "Accuracy: 0.189999997616 \t53\n",
      "Accuracy: 0.180000007153 \t54\n",
      "Accuracy: 0.180000007153 \t55\n",
      "Accuracy: 0.180000007153 \t56\n",
      "Accuracy: 0.180000007153 \t57\n",
      "Accuracy: 0.180000007153 \t58\n",
      "Accuracy: 0.189999997616 \t59\n",
      "Accuracy: 0.180000007153 \t60\n",
      "Accuracy: 0.170000016689 \t61\n",
      "Accuracy: 0.170000016689 \t62\n",
      "Accuracy: 0.160000026226 \t63\n",
      "Accuracy: 0.160000026226 \t64\n",
      "Accuracy: 0.160000026226 \t65\n",
      "Accuracy: 0.149999976158 \t66\n",
      "Accuracy: 0.149999976158 \t67\n",
      "Accuracy: 0.139999985695 \t68\n",
      "Accuracy: 0.120000004768 \t69\n",
      "Accuracy: 0.120000004768 \t70\n",
      "Accuracy: 0.120000004768 \t71\n",
      "Accuracy: 0.120000004768 \t72\n",
      "Accuracy: 0.120000004768 \t73\n",
      "Accuracy: 0.110000014305 \t74\n",
      "Accuracy: 0.110000014305 \t75\n",
      "Accuracy: 0.100000023842 \t76\n",
      "Accuracy: 0.100000023842 \t77\n",
      "Accuracy: 0.100000023842 \t78\n",
      "Accuracy: 0.0799999833107 \t79\n",
      "Accuracy: 0.0799999833107 \t80\n",
      "Accuracy: 0.0799999833107 \t81\n",
      "Accuracy: 0.0799999833107 \t82\n",
      "Accuracy: 0.0799999833107 \t83\n",
      "Accuracy: 0.0699999928474 \t84\n",
      "Accuracy: 0.0699999928474 \t85\n",
      "Accuracy: 0.0600000023842 \t86\n",
      "Accuracy: 0.0500000119209 \t87\n",
      "Accuracy: 0.0500000119209 \t88\n",
      "Accuracy: 0.0500000119209 \t89\n",
      "Accuracy: 0.0400000214577 \t90\n",
      "Accuracy: 0.0400000214577 \t91\n",
      "Accuracy: 0.0299999713898 \t92\n",
      "Accuracy: 0.0199999809265 \t93\n",
      "Accuracy: 0.0199999809265 \t94\n",
      "Accuracy: 0.0199999809265 \t95\n",
      "Accuracy: 0.0199999809265 \t96\n",
      "Accuracy: 0.0199999809265 \t97\n",
      "Accuracy: 0.00999999046326 \t98\n",
      "Accuracy: 0.00999999046326 \t99\n",
      "Accuracy: 0.0199999809265 \t0\n",
      "Accuracy: 0.0199999809265 \t1\n",
      "Accuracy: 0.0199999809265 \t2\n",
      "Accuracy: 0.0199999809265 \t3\n",
      "Accuracy: 0.0199999809265 \t4\n",
      "Accuracy: 0.0199999809265 \t5\n",
      "Accuracy: 0.00999999046326 \t6\n",
      "Accuracy: 0.00999999046326 \t7\n",
      "Accuracy: 0.00999999046326 \t8\n",
      "Accuracy: 0.00999999046326 \t9\n",
      "Accuracy: 0.0199999809265 \t10\n",
      "Accuracy: 0.0199999809265 \t11\n",
      "Accuracy: 0.0199999809265 \t12\n",
      "Accuracy: 0.0299999713898 \t13\n",
      "Accuracy: 0.0299999713898 \t14\n",
      "Accuracy: 0.0400000214577 \t15\n",
      "Accuracy: 0.0400000214577 \t16\n",
      "Accuracy: 0.0400000214577 \t17\n",
      "Accuracy: 0.0500000119209 \t18\n",
      "Accuracy: 0.0500000119209 \t19\n",
      "Accuracy: 0.0500000119209 \t20\n",
      "Accuracy: 0.0699999928474 \t21\n",
      "Accuracy: 0.0699999928474 \t22\n",
      "Accuracy: 0.0699999928474 \t23\n",
      "Accuracy: 0.0699999928474 \t24\n",
      "Accuracy: 0.0699999928474 \t25\n",
      "Accuracy: 0.0699999928474 \t26\n",
      "Accuracy: 0.0699999928474 \t27\n",
      "Accuracy: 0.0799999833107 \t28\n",
      "Accuracy: 0.0799999833107 \t29\n",
      "Accuracy: 0.0799999833107 \t30\n",
      "Accuracy: 0.089999973774 \t31\n",
      "Accuracy: 0.089999973774 \t32\n",
      "Accuracy: 0.100000023842 \t33\n",
      "Accuracy: 0.100000023842 \t34\n",
      "Accuracy: 0.110000014305 \t35\n",
      "Accuracy: 0.120000004768 \t36\n",
      "Accuracy: 0.129999995232 \t37\n",
      "Accuracy: 0.139999985695 \t38\n",
      "Accuracy: 0.149999976158 \t39\n",
      "Accuracy: 0.149999976158 \t40\n",
      "Accuracy: 0.149999976158 \t41\n",
      "Accuracy: 0.160000026226 \t42\n",
      "Accuracy: 0.160000026226 \t43\n",
      "Accuracy: 0.170000016689 \t44\n",
      "Accuracy: 0.149999976158 \t45\n",
      "Accuracy: 0.149999976158 \t46\n",
      "Accuracy: 0.139999985695 \t47\n",
      "Accuracy: 0.139999985695 \t48\n",
      "Accuracy: 0.139999985695 \t49\n",
      "Accuracy: 0.139999985695 \t50\n",
      "Accuracy: 0.129999995232 \t51\n",
      "Accuracy: 0.120000004768 \t52\n",
      "Accuracy: 0.120000004768 \t53\n",
      "Accuracy: 0.120000004768 \t54\n",
      "Accuracy: 0.129999995232 \t55\n",
      "Accuracy: 0.129999995232 \t56\n",
      "Accuracy: 0.129999995232 \t57\n",
      "Accuracy: 0.139999985695 \t58\n",
      "Accuracy: 0.139999985695 \t59\n",
      "Accuracy: 0.139999985695 \t60\n",
      "Accuracy: 0.139999985695 \t61\n",
      "Accuracy: 0.139999985695 \t62\n",
      "Accuracy: 0.139999985695 \t63\n",
      "Accuracy: 0.129999995232 \t64\n",
      "Accuracy: 0.129999995232 \t65\n",
      "Accuracy: 0.129999995232 \t66\n",
      "Accuracy: 0.120000004768 \t67\n",
      "Accuracy: 0.110000014305 \t68\n",
      "Accuracy: 0.110000014305 \t69\n",
      "Accuracy: 0.100000023842 \t70\n",
      "Accuracy: 0.100000023842 \t71\n",
      "Accuracy: 0.089999973774 \t72\n",
      "Accuracy: 0.0799999833107 \t73\n",
      "Accuracy: 0.0799999833107 \t74\n",
      "Accuracy: 0.0799999833107 \t75\n",
      "Accuracy: 0.0799999833107 \t76\n",
      "Accuracy: 0.089999973774 \t77\n",
      "Accuracy: 0.100000023842 \t78\n",
      "Accuracy: 0.100000023842 \t79\n",
      "Accuracy: 0.100000023842 \t80\n",
      "Accuracy: 0.100000023842 \t81\n",
      "Accuracy: 0.089999973774 \t82\n",
      "Accuracy: 0.0699999928474 \t83\n",
      "Accuracy: 0.0699999928474 \t84\n",
      "Accuracy: 0.0699999928474 \t85\n",
      "Accuracy: 0.0799999833107 \t86\n",
      "Accuracy: 0.0799999833107 \t87\n",
      "Accuracy: 0.0799999833107 \t88\n",
      "Accuracy: 0.0699999928474 \t89\n",
      "Accuracy: 0.0699999928474 \t90\n",
      "Accuracy: 0.0699999928474 \t91\n",
      "Accuracy: 0.0799999833107 \t92\n",
      "Accuracy: 0.0799999833107 \t93\n",
      "Accuracy: 0.0799999833107 \t94\n",
      "Accuracy: 0.0699999928474 \t95\n",
      "Accuracy: 0.0699999928474 \t96\n",
      "Accuracy: 0.0699999928474 \t97\n",
      "Accuracy: 0.0799999833107 \t98\n",
      "Accuracy: 0.0799999833107 \t99\n",
      "[(0.18999999761581421, 30), (0.17000001668930054, 44)]\n",
      "[1, 0, 3, 2]\n",
      "Final bead error: 0.049399971962\n",
      "Final bead error: 0.0475000143051\n",
      "[True, True, True, True, True]\n",
      "Accuracy: 0.0799999833107 \t0\n",
      "Accuracy: 0.0799999833107 \t1\n",
      "Accuracy: 0.0799999833107 \t2\n",
      "Accuracy: 0.0699999928474 \t3\n",
      "Accuracy: 0.0699999928474 \t4\n",
      "Accuracy: 0.0699999928474 \t5\n",
      "Accuracy: 0.0699999928474 \t6\n",
      "Accuracy: 0.0699999928474 \t7\n",
      "Accuracy: 0.0699999928474 \t8\n",
      "Accuracy: 0.0699999928474 \t9\n",
      "Accuracy: 0.0699999928474 \t10\n",
      "Accuracy: 0.0699999928474 \t11\n",
      "Accuracy: 0.0699999928474 \t12\n",
      "Accuracy: 0.0699999928474 \t13\n",
      "Accuracy: 0.0699999928474 \t14\n",
      "Accuracy: 0.0699999928474 \t15\n",
      "Accuracy: 0.0699999928474 \t16\n",
      "Accuracy: 0.0699999928474 \t17\n",
      "Accuracy: 0.0699999928474 \t18\n",
      "Accuracy: 0.0699999928474 \t19\n",
      "Accuracy: 0.0699999928474 \t20\n",
      "Accuracy: 0.0600000023842 \t21\n",
      "Accuracy: 0.0600000023842 \t22\n",
      "Accuracy: 0.0600000023842 \t23\n",
      "Accuracy: 0.0600000023842 \t24\n",
      "Accuracy: 0.0699999928474 \t25\n",
      "Accuracy: 0.0699999928474 \t26\n",
      "Accuracy: 0.0600000023842 \t27\n",
      "Accuracy: 0.0600000023842 \t28\n",
      "Accuracy: 0.0600000023842 \t29\n",
      "Accuracy: 0.0600000023842 \t30\n",
      "Accuracy: 0.0600000023842 \t31\n",
      "Accuracy: 0.0600000023842 \t32\n",
      "Accuracy: 0.0600000023842 \t33\n",
      "Accuracy: 0.0600000023842 \t34\n",
      "Accuracy: 0.0600000023842 \t35\n",
      "Accuracy: 0.0600000023842 \t36\n",
      "Accuracy: 0.0600000023842 \t37\n",
      "Accuracy: 0.0600000023842 \t38\n",
      "Accuracy: 0.0500000119209 \t39\n",
      "Accuracy: 0.0500000119209 \t40\n",
      "Accuracy: 0.0500000119209 \t41\n",
      "Accuracy: 0.0500000119209 \t42\n",
      "Accuracy: 0.0500000119209 \t43\n",
      "Accuracy: 0.0400000214577 \t44\n",
      "Accuracy: 0.0400000214577 \t45\n",
      "Accuracy: 0.0400000214577 \t46\n",
      "Accuracy: 0.0400000214577 \t47\n",
      "Accuracy: 0.0400000214577 \t48\n",
      "Accuracy: 0.0400000214577 \t49\n",
      "Accuracy: 0.0400000214577 \t50\n",
      "Accuracy: 0.0400000214577 \t51\n",
      "Accuracy: 0.0400000214577 \t52\n",
      "Accuracy: 0.0400000214577 \t53\n",
      "Accuracy: 0.0400000214577 \t54\n",
      "Accuracy: 0.0400000214577 \t55\n",
      "Accuracy: 0.0400000214577 \t56\n",
      "Accuracy: 0.0400000214577 \t57\n",
      "Accuracy: 0.0299999713898 \t58\n",
      "Accuracy: 0.0299999713898 \t59\n",
      "Accuracy: 0.0299999713898 \t60\n",
      "Accuracy: 0.0299999713898 \t61\n",
      "Accuracy: 0.0299999713898 \t62\n",
      "Accuracy: 0.0299999713898 \t63\n",
      "Accuracy: 0.0299999713898 \t64\n",
      "Accuracy: 0.0299999713898 \t65\n",
      "Accuracy: 0.0299999713898 \t66\n",
      "Accuracy: 0.0199999809265 \t67\n",
      "Accuracy: 0.0199999809265 \t68\n",
      "Accuracy: 0.0199999809265 \t69\n",
      "Accuracy: 0.0199999809265 \t70\n",
      "Accuracy: 0.0199999809265 \t71\n",
      "Accuracy: 0.0199999809265 \t72\n",
      "Accuracy: 0.0199999809265 \t73\n",
      "Accuracy: 0.00999999046326 \t74\n",
      "Accuracy: 0.00999999046326 \t75\n",
      "Accuracy: 0.00999999046326 \t76\n",
      "Accuracy: 0.00999999046326 \t77\n",
      "Accuracy: 0.00999999046326 \t78\n",
      "Accuracy: 0.00999999046326 \t79\n",
      "Accuracy: 0.00999999046326 \t80\n",
      "Accuracy: 0.0 \t81\n",
      "Accuracy: 0.0 \t82\n",
      "Accuracy: 0.0 \t83\n",
      "Accuracy: 0.0 \t84\n",
      "Accuracy: 0.0 \t85\n",
      "Accuracy: 0.0 \t86\n",
      "Accuracy: 0.0 \t87\n",
      "Accuracy: 0.0 \t88\n",
      "Accuracy: 0.0 \t89\n",
      "Accuracy: 0.0 \t90\n",
      "Accuracy: 0.0 \t91\n",
      "Accuracy: 0.0 \t92\n",
      "Accuracy: 0.0 \t93\n",
      "Accuracy: 0.0 \t94\n",
      "Accuracy: 0.0 \t95\n",
      "Accuracy: 0.0 \t96\n",
      "Accuracy: 0.0 \t97\n",
      "Accuracy: 0.0 \t98\n",
      "Accuracy: 0.0 \t99\n",
      "Accuracy: 0.0 \t0\n",
      "Accuracy: 0.0 \t1\n",
      "Accuracy: 0.0 \t2\n",
      "Accuracy: 0.0 \t3\n",
      "Accuracy: 0.0 \t4\n",
      "Accuracy: 0.0 \t5\n",
      "Accuracy: 0.0 \t6\n",
      "Accuracy: 0.0 \t7\n",
      "Accuracy: 0.0 \t8\n",
      "Accuracy: 0.0 \t9\n",
      "Accuracy: 0.0 \t10\n",
      "Accuracy: 0.0 \t11\n",
      "Accuracy: 0.0 \t12\n",
      "Accuracy: 0.00999999046326 \t13\n",
      "Accuracy: 0.00999999046326 \t14\n",
      "Accuracy: 0.00999999046326 \t15\n",
      "Accuracy: 0.00999999046326 \t16\n",
      "Accuracy: 0.00999999046326 \t17\n",
      "Accuracy: 0.00999999046326 \t18\n",
      "Accuracy: 0.00999999046326 \t19\n",
      "Accuracy: 0.0199999809265 \t20\n",
      "Accuracy: 0.0199999809265 \t21\n",
      "Accuracy: 0.0199999809265 \t22\n",
      "Accuracy: 0.0199999809265 \t23\n",
      "Accuracy: 0.0199999809265 \t24\n",
      "Accuracy: 0.0199999809265 \t25\n",
      "Accuracy: 0.0199999809265 \t26\n",
      "Accuracy: 0.0199999809265 \t27\n",
      "Accuracy: 0.0199999809265 \t28\n",
      "Accuracy: 0.0199999809265 \t29\n",
      "Accuracy: 0.0199999809265 \t30\n",
      "Accuracy: 0.0199999809265 \t31\n",
      "Accuracy: 0.0199999809265 \t32\n",
      "Accuracy: 0.0199999809265 \t33\n",
      "Accuracy: 0.0199999809265 \t34\n",
      "Accuracy: 0.0199999809265 \t35\n",
      "Accuracy: 0.0299999713898 \t36\n",
      "Accuracy: 0.0299999713898 \t37\n",
      "Accuracy: 0.0299999713898 \t38\n",
      "Accuracy: 0.0299999713898 \t39\n",
      "Accuracy: 0.0400000214577 \t40\n",
      "Accuracy: 0.0400000214577 \t41\n",
      "Accuracy: 0.0500000119209 \t42\n",
      "Accuracy: 0.0500000119209 \t43\n",
      "Accuracy: 0.0500000119209 \t44\n",
      "Accuracy: 0.0500000119209 \t45\n",
      "Accuracy: 0.0500000119209 \t46\n",
      "Accuracy: 0.0500000119209 \t47\n",
      "Accuracy: 0.0500000119209 \t48\n",
      "Accuracy: 0.0500000119209 \t49\n",
      "Accuracy: 0.0400000214577 \t50\n",
      "Accuracy: 0.0400000214577 \t51\n",
      "Accuracy: 0.0400000214577 \t52\n",
      "Accuracy: 0.0400000214577 \t53\n",
      "Accuracy: 0.0400000214577 \t54\n",
      "Accuracy: 0.0400000214577 \t55\n",
      "Accuracy: 0.0400000214577 \t56\n",
      "Accuracy: 0.0400000214577 \t57\n",
      "Accuracy: 0.0400000214577 \t58\n",
      "Accuracy: 0.0400000214577 \t59\n",
      "Accuracy: 0.0400000214577 \t60\n",
      "Accuracy: 0.0400000214577 \t61\n",
      "Accuracy: 0.0500000119209 \t62\n",
      "Accuracy: 0.0400000214577 \t63\n",
      "Accuracy: 0.0400000214577 \t64\n",
      "Accuracy: 0.0400000214577 \t65\n",
      "Accuracy: 0.0400000214577 \t66\n",
      "Accuracy: 0.0400000214577 \t67\n",
      "Accuracy: 0.0400000214577 \t68\n",
      "Accuracy: 0.0400000214577 \t69\n",
      "Accuracy: 0.0400000214577 \t70\n",
      "Accuracy: 0.0400000214577 \t71\n",
      "Accuracy: 0.0400000214577 \t72\n",
      "Accuracy: 0.0400000214577 \t73\n",
      "Accuracy: 0.0400000214577 \t74\n",
      "Accuracy: 0.0299999713898 \t75\n",
      "Accuracy: 0.0199999809265 \t76\n",
      "Accuracy: 0.00999999046326 \t77\n",
      "Accuracy: 0.00999999046326 \t78\n",
      "Accuracy: 0.00999999046326 \t79\n",
      "Accuracy: 0.00999999046326 \t80\n",
      "Accuracy: 0.00999999046326 \t81\n",
      "Accuracy: 0.00999999046326 \t82\n",
      "Accuracy: 0.00999999046326 \t83\n",
      "Accuracy: 0.00999999046326 \t84\n",
      "Accuracy: 0.00999999046326 \t85\n",
      "Accuracy: 0.00999999046326 \t86\n",
      "Accuracy: 0.0 \t87\n",
      "Accuracy: 0.0 \t88\n",
      "Accuracy: 0.0 \t89\n",
      "Accuracy: 0.0 \t90\n",
      "Accuracy: 0.0 \t91\n",
      "Accuracy: 0.0 \t92\n",
      "Accuracy: 0.0 \t93\n",
      "Accuracy: 0.0 \t94\n",
      "Accuracy: 0.0 \t95\n",
      "Accuracy: 0.0 \t96\n",
      "Accuracy: 0.0 \t97\n",
      "Accuracy: 0.0 \t98\n",
      "Accuracy: 0.00999999046326 \t99\n",
      "Accuracy: 0.0 \t0\n",
      "Accuracy: 0.0 \t1\n",
      "Accuracy: 0.0 \t2\n",
      "Accuracy: 0.0 \t3\n",
      "Accuracy: 0.0 \t4\n",
      "Accuracy: 0.0 \t5\n",
      "Accuracy: 0.0 \t6\n",
      "Accuracy: 0.0 \t7\n",
      "Accuracy: 0.0 \t8\n",
      "Accuracy: 0.0 \t9\n",
      "Accuracy: 0.0 \t10\n",
      "Accuracy: 0.0 \t11\n",
      "Accuracy: 0.0 \t12\n",
      "Accuracy: 0.0 \t13\n",
      "Accuracy: 0.0 \t14\n",
      "Accuracy: 0.0 \t15\n",
      "Accuracy: 0.0 \t16\n",
      "Accuracy: 0.0 \t17\n",
      "Accuracy: 0.0 \t18\n",
      "Accuracy: 0.0 \t19\n",
      "Accuracy: 0.0 \t20\n",
      "Accuracy: 0.0 \t21\n",
      "Accuracy: 0.0 \t22\n",
      "Accuracy: 0.0 \t23\n",
      "Accuracy: 0.0 \t24\n",
      "Accuracy: 0.0 \t25\n",
      "Accuracy: 0.0 \t26\n",
      "Accuracy: 0.0 \t27\n",
      "Accuracy: 0.0 \t28\n",
      "Accuracy: 0.0 \t29\n",
      "Accuracy: 0.0 \t30\n",
      "Accuracy: 0.0 \t31\n",
      "Accuracy: 0.0 \t32\n",
      "Accuracy: 0.0 \t33\n",
      "Accuracy: 0.0 \t34\n",
      "Accuracy: 0.0 \t35\n",
      "Accuracy: 0.0 \t36\n",
      "Accuracy: 0.0 \t37\n",
      "Accuracy: 0.0 \t38\n",
      "Accuracy: 0.0 \t39\n",
      "Accuracy: 0.0 \t40\n",
      "Accuracy: 0.0 \t41\n",
      "Accuracy: 0.0 \t42\n",
      "Accuracy: 0.0 \t43\n",
      "Accuracy: 0.0 \t44\n",
      "Accuracy: 0.0 \t45\n",
      "Accuracy: 0.0 \t46\n",
      "Accuracy: 0.0 \t47\n",
      "Accuracy: 0.0 \t48\n",
      "Accuracy: 0.0 \t49\n",
      "Accuracy: 0.0 \t50\n",
      "Accuracy: 0.0 \t51\n",
      "Accuracy: 0.0 \t52\n",
      "Accuracy: 0.0 \t53\n",
      "Accuracy: 0.0 \t54\n",
      "Accuracy: 0.0 \t55\n",
      "Accuracy: 0.0 \t56\n",
      "Accuracy: 0.0 \t57\n",
      "Accuracy: 0.0 \t58\n",
      "Accuracy: 0.0 \t59\n",
      "Accuracy: 0.0 \t60\n",
      "Accuracy: 0.0 \t61\n",
      "Accuracy: 0.0 \t62\n",
      "Accuracy: 0.0 \t63\n",
      "Accuracy: 0.0 \t64\n",
      "Accuracy: 0.0 \t65\n",
      "Accuracy: 0.0 \t66\n",
      "Accuracy: 0.0 \t67\n",
      "Accuracy: 0.0 \t68\n",
      "Accuracy: 0.0 \t69\n",
      "Accuracy: 0.0 \t70\n",
      "Accuracy: 0.0 \t71\n",
      "Accuracy: 0.0 \t72\n",
      "Accuracy: 0.0 \t73\n",
      "Accuracy: 0.0 \t74\n",
      "Accuracy: 0.0 \t75\n",
      "Accuracy: 0.0 \t76\n",
      "Accuracy: 0.0 \t77\n",
      "Accuracy: 0.0 \t78\n",
      "Accuracy: 0.0 \t79\n",
      "Accuracy: 0.0 \t80\n",
      "Accuracy: 0.0 \t81\n",
      "Accuracy: 0.0 \t82\n",
      "Accuracy: 0.0 \t83\n",
      "Accuracy: 0.0 \t84\n",
      "Accuracy: 0.0 \t85\n",
      "Accuracy: 0.0 \t86\n",
      "Accuracy: 0.00999999046326 \t87\n",
      "Accuracy: 0.00999999046326 \t88\n",
      "Accuracy: 0.0199999809265 \t89\n",
      "Accuracy: 0.0199999809265 \t90\n",
      "Accuracy: 0.0199999809265 \t91\n",
      "Accuracy: 0.0199999809265 \t92\n",
      "Accuracy: 0.0199999809265 \t93\n",
      "Accuracy: 0.0199999809265 \t94\n",
      "Accuracy: 0.0199999809265 \t95\n",
      "Accuracy: 0.0199999809265 \t96\n",
      "Accuracy: 0.0199999809265 \t97\n",
      "Accuracy: 0.0199999809265 \t98\n",
      "Accuracy: 0.0199999809265 \t99\n",
      "Accuracy: 0.00999999046326 \t0\n",
      "Accuracy: 0.00999999046326 \t1\n",
      "Accuracy: 0.0199999809265 \t2\n",
      "Accuracy: 0.0199999809265 \t3\n",
      "Accuracy: 0.0199999809265 \t4\n",
      "Accuracy: 0.00999999046326 \t5\n",
      "Accuracy: 0.00999999046326 \t6\n",
      "Accuracy: 0.00999999046326 \t7\n",
      "Accuracy: 0.00999999046326 \t8\n",
      "Accuracy: 0.00999999046326 \t9\n",
      "Accuracy: 0.0199999809265 \t10\n",
      "Accuracy: 0.0299999713898 \t11\n",
      "Accuracy: 0.0299999713898 \t12\n",
      "Accuracy: 0.0299999713898 \t13\n",
      "Accuracy: 0.0299999713898 \t14\n",
      "Accuracy: 0.0299999713898 \t15\n",
      "Accuracy: 0.0299999713898 \t16\n",
      "Accuracy: 0.0299999713898 \t17\n",
      "Accuracy: 0.0400000214577 \t18\n",
      "Accuracy: 0.0500000119209 \t19\n",
      "Accuracy: 0.0500000119209 \t20\n",
      "Accuracy: 0.0500000119209 \t21\n",
      "Accuracy: 0.0500000119209 \t22\n",
      "Accuracy: 0.0500000119209 \t23\n",
      "Accuracy: 0.0500000119209 \t24\n",
      "Accuracy: 0.0500000119209 \t25\n",
      "Accuracy: 0.0500000119209 \t26\n",
      "Accuracy: 0.0500000119209 \t27\n",
      "Accuracy: 0.0500000119209 \t28\n",
      "Accuracy: 0.0500000119209 \t29\n",
      "Accuracy: 0.0500000119209 \t30\n",
      "Accuracy: 0.0500000119209 \t31\n",
      "Accuracy: 0.0500000119209 \t32\n",
      "Accuracy: 0.0500000119209 \t33\n",
      "Accuracy: 0.0600000023842 \t34\n",
      "Accuracy: 0.0600000023842 \t35\n",
      "Accuracy: 0.0600000023842 \t36\n",
      "Accuracy: 0.0600000023842 \t37\n",
      "Accuracy: 0.0600000023842 \t38\n",
      "Accuracy: 0.0699999928474 \t39\n",
      "Accuracy: 0.0799999833107 \t40\n",
      "Accuracy: 0.0799999833107 \t41\n",
      "Accuracy: 0.0799999833107 \t42\n",
      "Accuracy: 0.0799999833107 \t43\n",
      "Accuracy: 0.0799999833107 \t44\n",
      "Accuracy: 0.0799999833107 \t45\n",
      "Accuracy: 0.0799999833107 \t46\n",
      "Accuracy: 0.0799999833107 \t47\n",
      "Accuracy: 0.0799999833107 \t48\n",
      "Accuracy: 0.0799999833107 \t49\n",
      "Accuracy: 0.089999973774 \t50\n",
      "Accuracy: 0.089999973774 \t51\n",
      "Accuracy: 0.089999973774 \t52\n",
      "Accuracy: 0.089999973774 \t53\n",
      "Accuracy: 0.089999973774 \t54\n",
      "Accuracy: 0.089999973774 \t55\n",
      "Accuracy: 0.089999973774 \t56\n",
      "Accuracy: 0.089999973774 \t57\n",
      "Accuracy: 0.089999973774 \t58\n",
      "Accuracy: 0.089999973774 \t59\n",
      "Accuracy: 0.089999973774 \t60\n",
      "Accuracy: 0.089999973774 \t61\n",
      "Accuracy: 0.089999973774 \t62\n",
      "Accuracy: 0.089999973774 \t63\n",
      "Accuracy: 0.089999973774 \t64\n",
      "Accuracy: 0.089999973774 \t65\n",
      "Accuracy: 0.089999973774 \t66\n",
      "Accuracy: 0.089999973774 \t67\n",
      "Accuracy: 0.089999973774 \t68\n",
      "Accuracy: 0.089999973774 \t69\n",
      "Accuracy: 0.089999973774 \t70\n",
      "Accuracy: 0.089999973774 \t71\n",
      "Accuracy: 0.089999973774 \t72\n",
      "Accuracy: 0.089999973774 \t73\n",
      "Accuracy: 0.089999973774 \t74\n",
      "Accuracy: 0.089999973774 \t75\n",
      "Accuracy: 0.089999973774 \t76\n",
      "Accuracy: 0.089999973774 \t77\n",
      "Accuracy: 0.089999973774 \t78\n",
      "Accuracy: 0.089999973774 \t79\n",
      "Accuracy: 0.089999973774 \t80\n",
      "Accuracy: 0.089999973774 \t81\n",
      "Accuracy: 0.089999973774 \t82\n",
      "Accuracy: 0.089999973774 \t83\n",
      "Accuracy: 0.089999973774 \t84\n",
      "Accuracy: 0.089999973774 \t85\n",
      "Accuracy: 0.089999973774 \t86\n",
      "Accuracy: 0.0799999833107 \t87\n",
      "Accuracy: 0.0799999833107 \t88\n",
      "Accuracy: 0.0799999833107 \t89\n",
      "Accuracy: 0.0799999833107 \t90\n",
      "Accuracy: 0.0799999833107 \t91\n",
      "Accuracy: 0.089999973774 \t92\n",
      "Accuracy: 0.089999973774 \t93\n",
      "Accuracy: 0.089999973774 \t94\n",
      "Accuracy: 0.089999973774 \t95\n",
      "Accuracy: 0.089999973774 \t96\n",
      "Accuracy: 0.089999973774 \t97\n",
      "Accuracy: 0.089999973774 \t98\n",
      "Accuracy: 0.100000023842 \t99\n",
      "[(0.079999983310699463, 0), (0.050000011920928955, 42), (0.019999980926513672, 89), (0.10000002384185791, 99)]\n",
      "[0, 1]\n",
      "Final bead error: 0.0468000173569\n",
      "[True, True, True]\n",
      "Accuracy: 0.120000004768 \t0\n",
      "Accuracy: 0.120000004768 \t1\n",
      "Accuracy: 0.120000004768 \t2\n",
      "Accuracy: 0.120000004768 \t3\n",
      "Accuracy: 0.129999995232 \t4\n",
      "Accuracy: 0.129999995232 \t5\n",
      "Accuracy: 0.129999995232 \t6\n",
      "Accuracy: 0.129999995232 \t7\n",
      "Accuracy: 0.129999995232 \t8\n",
      "Accuracy: 0.129999995232 \t9\n",
      "Accuracy: 0.129999995232 \t10\n",
      "Accuracy: 0.129999995232 \t11\n",
      "Accuracy: 0.129999995232 \t12\n",
      "Accuracy: 0.129999995232 \t13\n",
      "Accuracy: 0.129999995232 \t14\n",
      "Accuracy: 0.129999995232 \t15\n",
      "Accuracy: 0.129999995232 \t16\n",
      "Accuracy: 0.129999995232 \t17\n",
      "Accuracy: 0.129999995232 \t18\n",
      "Accuracy: 0.129999995232 \t19\n",
      "Accuracy: 0.129999995232 \t20\n",
      "Accuracy: 0.129999995232 \t21\n",
      "Accuracy: 0.129999995232 \t22\n",
      "Accuracy: 0.139999985695 \t23\n",
      "Accuracy: 0.139999985695 \t24\n",
      "Accuracy: 0.139999985695 \t25\n",
      "Accuracy: 0.139999985695 \t26\n",
      "Accuracy: 0.139999985695 \t27\n",
      "Accuracy: 0.139999985695 \t28\n",
      "Accuracy: 0.139999985695 \t29\n",
      "Accuracy: 0.139999985695 \t30\n",
      "Accuracy: 0.139999985695 \t31\n",
      "Accuracy: 0.139999985695 \t32\n",
      "Accuracy: 0.139999985695 \t33\n",
      "Accuracy: 0.149999976158 \t34\n",
      "Accuracy: 0.160000026226 \t35\n",
      "Accuracy: 0.160000026226 \t36\n",
      "Accuracy: 0.160000026226 \t37\n",
      "Accuracy: 0.170000016689 \t38\n",
      "Accuracy: 0.170000016689 \t39\n",
      "Accuracy: 0.170000016689 \t40\n",
      "Accuracy: 0.170000016689 \t41\n",
      "Accuracy: 0.170000016689 \t42\n",
      "Accuracy: 0.170000016689 \t43\n",
      "Accuracy: 0.170000016689 \t44\n",
      "Accuracy: 0.180000007153 \t45\n",
      "Accuracy: 0.170000016689 \t46\n",
      "Accuracy: 0.170000016689 \t47\n",
      "Accuracy: 0.160000026226 \t48\n",
      "Accuracy: 0.149999976158 \t49\n",
      "Accuracy: 0.149999976158 \t50\n",
      "Accuracy: 0.149999976158 \t51\n",
      "Accuracy: 0.149999976158 \t52\n",
      "Accuracy: 0.149999976158 \t53\n",
      "Accuracy: 0.149999976158 \t54\n",
      "Accuracy: 0.149999976158 \t55\n",
      "Accuracy: 0.149999976158 \t56\n",
      "Accuracy: 0.149999976158 \t57\n",
      "Accuracy: 0.149999976158 \t58\n",
      "Accuracy: 0.149999976158 \t59\n",
      "Accuracy: 0.149999976158 \t60\n",
      "Accuracy: 0.149999976158 \t61\n",
      "Accuracy: 0.149999976158 \t62\n",
      "Accuracy: 0.149999976158 \t63\n",
      "Accuracy: 0.139999985695 \t64\n",
      "Accuracy: 0.129999995232 \t65\n",
      "Accuracy: 0.120000004768 \t66\n",
      "Accuracy: 0.110000014305 \t67\n",
      "Accuracy: 0.110000014305 \t68\n",
      "Accuracy: 0.110000014305 \t69\n",
      "Accuracy: 0.110000014305 \t70\n",
      "Accuracy: 0.110000014305 \t71\n",
      "Accuracy: 0.110000014305 \t72\n",
      "Accuracy: 0.120000004768 \t73\n",
      "Accuracy: 0.120000004768 \t74\n",
      "Accuracy: 0.120000004768 \t75\n",
      "Accuracy: 0.120000004768 \t76\n",
      "Accuracy: 0.120000004768 \t77\n",
      "Accuracy: 0.120000004768 \t78\n",
      "Accuracy: 0.120000004768 \t79\n",
      "Accuracy: 0.089999973774 \t80\n",
      "Accuracy: 0.0799999833107 \t81\n",
      "Accuracy: 0.0799999833107 \t82\n",
      "Accuracy: 0.0799999833107 \t83\n",
      "Accuracy: 0.0799999833107 \t84\n",
      "Accuracy: 0.0600000023842 \t85\n",
      "Accuracy: 0.0600000023842 \t86\n",
      "Accuracy: 0.0600000023842 \t87\n",
      "Accuracy: 0.0600000023842 \t88\n",
      "Accuracy: 0.0600000023842 \t89\n",
      "Accuracy: 0.0600000023842 \t90\n",
      "Accuracy: 0.0600000023842 \t91\n",
      "Accuracy: 0.0500000119209 \t92\n",
      "Accuracy: 0.0500000119209 \t93\n",
      "Accuracy: 0.0500000119209 \t94\n",
      "Accuracy: 0.0400000214577 \t95\n",
      "Accuracy: 0.0299999713898 \t96\n",
      "Accuracy: 0.0199999809265 \t97\n",
      "Accuracy: 0.0199999809265 \t98\n",
      "Accuracy: 0.0199999809265 \t99\n",
      "Accuracy: 0.00999999046326 \t0\n",
      "Accuracy: 0.00999999046326 \t1\n",
      "Accuracy: 0.00999999046326 \t2\n",
      "Accuracy: 0.00999999046326 \t3\n",
      "Accuracy: 0.00999999046326 \t4\n",
      "Accuracy: 0.00999999046326 \t5\n",
      "Accuracy: 0.00999999046326 \t6\n",
      "Accuracy: 0.00999999046326 \t7\n",
      "Accuracy: 0.00999999046326 \t8\n",
      "Accuracy: 0.00999999046326 \t9\n",
      "Accuracy: 0.0199999809265 \t10\n",
      "Accuracy: 0.0199999809265 \t11\n",
      "Accuracy: 0.0199999809265 \t12\n",
      "Accuracy: 0.0199999809265 \t13\n",
      "Accuracy: 0.0199999809265 \t14\n",
      "Accuracy: 0.0199999809265 \t15\n",
      "Accuracy: 0.0199999809265 \t16\n",
      "Accuracy: 0.0199999809265 \t17\n",
      "Accuracy: 0.0199999809265 \t18\n",
      "Accuracy: 0.0400000214577 \t19\n",
      "Accuracy: 0.0400000214577 \t20\n",
      "Accuracy: 0.0400000214577 \t21\n",
      "Accuracy: 0.0400000214577 \t22\n",
      "Accuracy: 0.0400000214577 \t23\n",
      "Accuracy: 0.0400000214577 \t24\n",
      "Accuracy: 0.0500000119209 \t25\n",
      "Accuracy: 0.0600000023842 \t26\n",
      "Accuracy: 0.0699999928474 \t27\n",
      "Accuracy: 0.089999973774 \t28\n",
      "Accuracy: 0.089999973774 \t29\n",
      "Accuracy: 0.089999973774 \t30\n",
      "Accuracy: 0.089999973774 \t31\n",
      "Accuracy: 0.110000014305 \t32\n",
      "Accuracy: 0.120000004768 \t33\n",
      "Accuracy: 0.129999995232 \t34\n",
      "Accuracy: 0.129999995232 \t35\n",
      "Accuracy: 0.129999995232 \t36\n",
      "Accuracy: 0.129999995232 \t37\n",
      "Accuracy: 0.129999995232 \t38\n",
      "Accuracy: 0.129999995232 \t39\n",
      "Accuracy: 0.129999995232 \t40\n",
      "Accuracy: 0.129999995232 \t41\n",
      "Accuracy: 0.129999995232 \t42\n",
      "Accuracy: 0.129999995232 \t43\n",
      "Accuracy: 0.120000004768 \t44\n",
      "Accuracy: 0.120000004768 \t45\n",
      "Accuracy: 0.120000004768 \t46\n",
      "Accuracy: 0.120000004768 \t47\n",
      "Accuracy: 0.120000004768 \t48\n",
      "Accuracy: 0.120000004768 \t49\n",
      "Accuracy: 0.120000004768 \t50\n",
      "Accuracy: 0.120000004768 \t51\n",
      "Accuracy: 0.110000014305 \t52\n",
      "Accuracy: 0.110000014305 \t53\n",
      "Accuracy: 0.110000014305 \t54\n",
      "Accuracy: 0.120000004768 \t55\n",
      "Accuracy: 0.110000014305 \t56\n",
      "Accuracy: 0.100000023842 \t57\n",
      "Accuracy: 0.100000023842 \t58\n",
      "Accuracy: 0.100000023842 \t59\n",
      "Accuracy: 0.100000023842 \t60\n",
      "Accuracy: 0.089999973774 \t61\n",
      "Accuracy: 0.089999973774 \t62\n",
      "Accuracy: 0.089999973774 \t63\n",
      "Accuracy: 0.089999973774 \t64\n",
      "Accuracy: 0.089999973774 \t65\n",
      "Accuracy: 0.089999973774 \t66\n",
      "Accuracy: 0.089999973774 \t67\n",
      "Accuracy: 0.089999973774 \t68\n",
      "Accuracy: 0.0799999833107 \t69\n",
      "Accuracy: 0.0799999833107 \t70\n",
      "Accuracy: 0.0799999833107 \t71\n",
      "Accuracy: 0.0799999833107 \t72\n",
      "Accuracy: 0.0799999833107 \t73\n",
      "Accuracy: 0.0799999833107 \t74\n",
      "Accuracy: 0.0799999833107 \t75\n",
      "Accuracy: 0.0799999833107 \t76\n",
      "Accuracy: 0.0799999833107 \t77\n",
      "Accuracy: 0.0799999833107 \t78\n",
      "Accuracy: 0.089999973774 \t79\n",
      "Accuracy: 0.089999973774 \t80\n",
      "Accuracy: 0.0799999833107 \t81\n",
      "Accuracy: 0.0799999833107 \t82\n",
      "Accuracy: 0.0799999833107 \t83\n",
      "Accuracy: 0.089999973774 \t84\n",
      "Accuracy: 0.089999973774 \t85\n",
      "Accuracy: 0.0799999833107 \t86\n",
      "Accuracy: 0.0799999833107 \t87\n",
      "Accuracy: 0.0799999833107 \t88\n",
      "Accuracy: 0.0799999833107 \t89\n",
      "Accuracy: 0.0799999833107 \t90\n",
      "Accuracy: 0.0799999833107 \t91\n",
      "Accuracy: 0.0799999833107 \t92\n",
      "Accuracy: 0.0799999833107 \t93\n",
      "Accuracy: 0.089999973774 \t94\n",
      "Accuracy: 0.089999973774 \t95\n",
      "Accuracy: 0.089999973774 \t96\n",
      "Accuracy: 0.0799999833107 \t97\n",
      "Accuracy: 0.0799999833107 \t98\n",
      "Accuracy: 0.0799999833107 \t99\n",
      "[(0.18000000715255737, 45), (0.12999999523162842, 34)]\n",
      "[1, 0, 3, 2]\n",
      "Final bead error: 0.0460000038147\n",
      "Final bead error: 0.043799996376\n",
      "[True, True, True, True, True]\n",
      "Accuracy: 0.0600000023842 \t0\n",
      "Accuracy: 0.0600000023842 \t1\n",
      "Accuracy: 0.0600000023842 \t2\n",
      "Accuracy: 0.0600000023842 \t3\n",
      "Accuracy: 0.0500000119209 \t4\n",
      "Accuracy: 0.0500000119209 \t5\n",
      "Accuracy: 0.0500000119209 \t6\n",
      "Accuracy: 0.0500000119209 \t7\n",
      "Accuracy: 0.0600000023842 \t8\n",
      "Accuracy: 0.0600000023842 \t9\n",
      "Accuracy: 0.0600000023842 \t10\n",
      "Accuracy: 0.0600000023842 \t11\n",
      "Accuracy: 0.0600000023842 \t12\n",
      "Accuracy: 0.0600000023842 \t13\n",
      "Accuracy: 0.0600000023842 \t14\n",
      "Accuracy: 0.0600000023842 \t15\n",
      "Accuracy: 0.0500000119209 \t16\n",
      "Accuracy: 0.0500000119209 \t17\n",
      "Accuracy: 0.0500000119209 \t18\n",
      "Accuracy: 0.0500000119209 \t19\n",
      "Accuracy: 0.0500000119209 \t20\n",
      "Accuracy: 0.0500000119209 \t21\n",
      "Accuracy: 0.0500000119209 \t22\n",
      "Accuracy: 0.0500000119209 \t23\n",
      "Accuracy: 0.0500000119209 \t24\n",
      "Accuracy: 0.0600000023842 \t25\n",
      "Accuracy: 0.0600000023842 \t26\n",
      "Accuracy: 0.0500000119209 \t27\n",
      "Accuracy: 0.0500000119209 \t28\n",
      "Accuracy: 0.0500000119209 \t29\n",
      "Accuracy: 0.0500000119209 \t30\n",
      "Accuracy: 0.0600000023842 \t31\n",
      "Accuracy: 0.0600000023842 \t32\n",
      "Accuracy: 0.0699999928474 \t33\n",
      "Accuracy: 0.0699999928474 \t34\n",
      "Accuracy: 0.0699999928474 \t35\n",
      "Accuracy: 0.0600000023842 \t36\n",
      "Accuracy: 0.0600000023842 \t37\n",
      "Accuracy: 0.0600000023842 \t38\n",
      "Accuracy: 0.0600000023842 \t39\n",
      "Accuracy: 0.0600000023842 \t40\n",
      "Accuracy: 0.0600000023842 \t41\n",
      "Accuracy: 0.0600000023842 \t42\n",
      "Accuracy: 0.0600000023842 \t43\n",
      "Accuracy: 0.0600000023842 \t44\n",
      "Accuracy: 0.0600000023842 \t45\n",
      "Accuracy: 0.0600000023842 \t46\n",
      "Accuracy: 0.0600000023842 \t47\n",
      "Accuracy: 0.0600000023842 \t48\n",
      "Accuracy: 0.0600000023842 \t49\n",
      "Accuracy: 0.0600000023842 \t50\n",
      "Accuracy: 0.0600000023842 \t51\n",
      "Accuracy: 0.0600000023842 \t52\n",
      "Accuracy: 0.0600000023842 \t53\n",
      "Accuracy: 0.0600000023842 \t54\n",
      "Accuracy: 0.0600000023842 \t55\n",
      "Accuracy: 0.0600000023842 \t56\n",
      "Accuracy: 0.0600000023842 \t57\n",
      "Accuracy: 0.0600000023842 \t58\n",
      "Accuracy: 0.0600000023842 \t59\n",
      "Accuracy: 0.0600000023842 \t60\n",
      "Accuracy: 0.0600000023842 \t61\n",
      "Accuracy: 0.0600000023842 \t62\n",
      "Accuracy: 0.0600000023842 \t63\n",
      "Accuracy: 0.0600000023842 \t64\n",
      "Accuracy: 0.0600000023842 \t65\n",
      "Accuracy: 0.0600000023842 \t66\n",
      "Accuracy: 0.0600000023842 \t67\n",
      "Accuracy: 0.0600000023842 \t68\n",
      "Accuracy: 0.0600000023842 \t69\n",
      "Accuracy: 0.0600000023842 \t70\n",
      "Accuracy: 0.0600000023842 \t71\n",
      "Accuracy: 0.0600000023842 \t72\n",
      "Accuracy: 0.0600000023842 \t73\n",
      "Accuracy: 0.0600000023842 \t74\n",
      "Accuracy: 0.0600000023842 \t75\n",
      "Accuracy: 0.0600000023842 \t76\n",
      "Accuracy: 0.0600000023842 \t77\n",
      "Accuracy: 0.0500000119209 \t78\n",
      "Accuracy: 0.0500000119209 \t79\n",
      "Accuracy: 0.0500000119209 \t80\n",
      "Accuracy: 0.0500000119209 \t81\n",
      "Accuracy: 0.0500000119209 \t82\n",
      "Accuracy: 0.0299999713898 \t83\n",
      "Accuracy: 0.0299999713898 \t84\n",
      "Accuracy: 0.0299999713898 \t85\n",
      "Accuracy: 0.0299999713898 \t86\n",
      "Accuracy: 0.0199999809265 \t87\n",
      "Accuracy: 0.0199999809265 \t88\n",
      "Accuracy: 0.0199999809265 \t89\n",
      "Accuracy: 0.0199999809265 \t90\n",
      "Accuracy: 0.00999999046326 \t91\n",
      "Accuracy: 0.00999999046326 \t92\n",
      "Accuracy: 0.00999999046326 \t93\n",
      "Accuracy: 0.00999999046326 \t94\n",
      "Accuracy: 0.00999999046326 \t95\n",
      "Accuracy: 0.00999999046326 \t96\n",
      "Accuracy: 0.00999999046326 \t97\n",
      "Accuracy: 0.00999999046326 \t98\n",
      "Accuracy: 0.00999999046326 \t99\n",
      "Accuracy: 0.00999999046326 \t0\n",
      "Accuracy: 0.00999999046326 \t1\n",
      "Accuracy: 0.00999999046326 \t2\n",
      "Accuracy: 0.00999999046326 \t3\n",
      "Accuracy: 0.00999999046326 \t4\n",
      "Accuracy: 0.00999999046326 \t5\n",
      "Accuracy: 0.00999999046326 \t6\n",
      "Accuracy: 0.00999999046326 \t7\n",
      "Accuracy: 0.00999999046326 \t8\n",
      "Accuracy: 0.00999999046326 \t9\n",
      "Accuracy: 0.00999999046326 \t10\n",
      "Accuracy: 0.0 \t11\n",
      "Accuracy: 0.0 \t12\n",
      "Accuracy: 0.0 \t13\n",
      "Accuracy: 0.0 \t14\n",
      "Accuracy: 0.0 \t15\n",
      "Accuracy: 0.0 \t16\n",
      "Accuracy: 0.0 \t17\n",
      "Accuracy: 0.0 \t18\n",
      "Accuracy: 0.0 \t19\n",
      "Accuracy: 0.0 \t20\n",
      "Accuracy: 0.0 \t21\n",
      "Accuracy: 0.0 \t22\n",
      "Accuracy: 0.0 \t23\n",
      "Accuracy: 0.0 \t24\n",
      "Accuracy: 0.0 \t25\n",
      "Accuracy: 0.00999999046326 \t26\n",
      "Accuracy: 0.00999999046326 \t27\n",
      "Accuracy: 0.00999999046326 \t28\n",
      "Accuracy: 0.00999999046326 \t29\n",
      "Accuracy: 0.00999999046326 \t30\n",
      "Accuracy: 0.00999999046326 \t31\n",
      "Accuracy: 0.00999999046326 \t32\n",
      "Accuracy: 0.00999999046326 \t33\n",
      "Accuracy: 0.00999999046326 \t34\n",
      "Accuracy: 0.00999999046326 \t35\n",
      "Accuracy: 0.0199999809265 \t36\n",
      "Accuracy: 0.0199999809265 \t37\n",
      "Accuracy: 0.0199999809265 \t38\n",
      "Accuracy: 0.0199999809265 \t39\n",
      "Accuracy: 0.0199999809265 \t40\n",
      "Accuracy: 0.0199999809265 \t41\n",
      "Accuracy: 0.0199999809265 \t42\n",
      "Accuracy: 0.0199999809265 \t43\n",
      "Accuracy: 0.0199999809265 \t44\n",
      "Accuracy: 0.0199999809265 \t45\n",
      "Accuracy: 0.0199999809265 \t46\n",
      "Accuracy: 0.0199999809265 \t47\n",
      "Accuracy: 0.0199999809265 \t48\n",
      "Accuracy: 0.0199999809265 \t49\n",
      "Accuracy: 0.0199999809265 \t50\n",
      "Accuracy: 0.0199999809265 \t51\n",
      "Accuracy: 0.0199999809265 \t52\n",
      "Accuracy: 0.0199999809265 \t53\n",
      "Accuracy: 0.0199999809265 \t54\n",
      "Accuracy: 0.0199999809265 \t55\n",
      "Accuracy: 0.0199999809265 \t56\n",
      "Accuracy: 0.0199999809265 \t57\n",
      "Accuracy: 0.0199999809265 \t58\n",
      "Accuracy: 0.0199999809265 \t59\n",
      "Accuracy: 0.0199999809265 \t60\n",
      "Accuracy: 0.0199999809265 \t61\n",
      "Accuracy: 0.0199999809265 \t62\n",
      "Accuracy: 0.0199999809265 \t63\n",
      "Accuracy: 0.0199999809265 \t64\n",
      "Accuracy: 0.0199999809265 \t65\n",
      "Accuracy: 0.00999999046326 \t66\n",
      "Accuracy: 0.00999999046326 \t67\n",
      "Accuracy: 0.00999999046326 \t68\n",
      "Accuracy: 0.00999999046326 \t69\n",
      "Accuracy: 0.00999999046326 \t70\n",
      "Accuracy: 0.00999999046326 \t71\n",
      "Accuracy: 0.00999999046326 \t72\n",
      "Accuracy: 0.00999999046326 \t73\n",
      "Accuracy: 0.00999999046326 \t74\n",
      "Accuracy: 0.00999999046326 \t75\n",
      "Accuracy: 0.00999999046326 \t76\n",
      "Accuracy: 0.00999999046326 \t77\n",
      "Accuracy: 0.00999999046326 \t78\n",
      "Accuracy: 0.00999999046326 \t79\n",
      "Accuracy: 0.00999999046326 \t80\n",
      "Accuracy: 0.00999999046326 \t81\n",
      "Accuracy: 0.00999999046326 \t82\n",
      "Accuracy: 0.0 \t83\n",
      "Accuracy: 0.0 \t84\n",
      "Accuracy: 0.0 \t85\n",
      "Accuracy: 0.0 \t86\n",
      "Accuracy: 0.0 \t87\n",
      "Accuracy: 0.0 \t88\n",
      "Accuracy: 0.0 \t89\n",
      "Accuracy: 0.0 \t90\n",
      "Accuracy: 0.0 \t91\n",
      "Accuracy: 0.0 \t92\n",
      "Accuracy: 0.0 \t93\n",
      "Accuracy: 0.0 \t94\n",
      "Accuracy: 0.0 \t95\n",
      "Accuracy: 0.0 \t96\n",
      "Accuracy: 0.0 \t97\n",
      "Accuracy: 0.0 \t98\n",
      "Accuracy: 0.0 \t99\n",
      "Accuracy: 0.00999999046326 \t0\n",
      "Accuracy: 0.00999999046326 \t1\n",
      "Accuracy: 0.00999999046326 \t2\n",
      "Accuracy: 0.00999999046326 \t3\n",
      "Accuracy: 0.00999999046326 \t4\n",
      "Accuracy: 0.00999999046326 \t5\n",
      "Accuracy: 0.00999999046326 \t6\n",
      "Accuracy: 0.00999999046326 \t7\n",
      "Accuracy: 0.00999999046326 \t8\n",
      "Accuracy: 0.00999999046326 \t9\n",
      "Accuracy: 0.00999999046326 \t10\n",
      "Accuracy: 0.00999999046326 \t11\n",
      "Accuracy: 0.00999999046326 \t12\n",
      "Accuracy: 0.00999999046326 \t13\n",
      "Accuracy: 0.00999999046326 \t14\n",
      "Accuracy: 0.00999999046326 \t15\n",
      "Accuracy: 0.00999999046326 \t16\n",
      "Accuracy: 0.00999999046326 \t17\n",
      "Accuracy: 0.00999999046326 \t18\n",
      "Accuracy: 0.00999999046326 \t19\n",
      "Accuracy: 0.00999999046326 \t20\n",
      "Accuracy: 0.00999999046326 \t21\n",
      "Accuracy: 0.00999999046326 \t22\n",
      "Accuracy: 0.00999999046326 \t23\n",
      "Accuracy: 0.00999999046326 \t24\n",
      "Accuracy: 0.00999999046326 \t25\n",
      "Accuracy: 0.00999999046326 \t26\n",
      "Accuracy: 0.00999999046326 \t27\n",
      "Accuracy: 0.00999999046326 \t28\n",
      "Accuracy: 0.00999999046326 \t29\n",
      "Accuracy: 0.00999999046326 \t30\n",
      "Accuracy: 0.00999999046326 \t31\n",
      "Accuracy: 0.00999999046326 \t32\n",
      "Accuracy: 0.00999999046326 \t33\n",
      "Accuracy: 0.00999999046326 \t34\n",
      "Accuracy: 0.00999999046326 \t35\n",
      "Accuracy: 0.00999999046326 \t36\n",
      "Accuracy: 0.00999999046326 \t37\n",
      "Accuracy: 0.00999999046326 \t38\n",
      "Accuracy: 0.00999999046326 \t39\n",
      "Accuracy: 0.00999999046326 \t40\n",
      "Accuracy: 0.00999999046326 \t41\n",
      "Accuracy: 0.00999999046326 \t42\n",
      "Accuracy: 0.00999999046326 \t43\n",
      "Accuracy: 0.00999999046326 \t44\n",
      "Accuracy: 0.00999999046326 \t45\n",
      "Accuracy: 0.00999999046326 \t46\n",
      "Accuracy: 0.00999999046326 \t47\n",
      "Accuracy: 0.00999999046326 \t48\n",
      "Accuracy: 0.0199999809265 \t49\n",
      "Accuracy: 0.0199999809265 \t50\n",
      "Accuracy: 0.0199999809265 \t51\n",
      "Accuracy: 0.0199999809265 \t52\n",
      "Accuracy: 0.0199999809265 \t53\n",
      "Accuracy: 0.0199999809265 \t54\n",
      "Accuracy: 0.0199999809265 \t55\n",
      "Accuracy: 0.0199999809265 \t56\n",
      "Accuracy: 0.0199999809265 \t57\n",
      "Accuracy: 0.0199999809265 \t58\n",
      "Accuracy: 0.0199999809265 \t59\n",
      "Accuracy: 0.0199999809265 \t60\n",
      "Accuracy: 0.0199999809265 \t61\n",
      "Accuracy: 0.0199999809265 \t62\n",
      "Accuracy: 0.0199999809265 \t63\n",
      "Accuracy: 0.0199999809265 \t64\n",
      "Accuracy: 0.0199999809265 \t65\n",
      "Accuracy: 0.0199999809265 \t66\n",
      "Accuracy: 0.0199999809265 \t67\n",
      "Accuracy: 0.0199999809265 \t68\n",
      "Accuracy: 0.0199999809265 \t69\n",
      "Accuracy: 0.0199999809265 \t70\n",
      "Accuracy: 0.0199999809265 \t71\n",
      "Accuracy: 0.0199999809265 \t72\n",
      "Accuracy: 0.0199999809265 \t73\n",
      "Accuracy: 0.0199999809265 \t74\n",
      "Accuracy: 0.0199999809265 \t75\n",
      "Accuracy: 0.0199999809265 \t76\n",
      "Accuracy: 0.0199999809265 \t77\n",
      "Accuracy: 0.0199999809265 \t78\n",
      "Accuracy: 0.0199999809265 \t79\n",
      "Accuracy: 0.0199999809265 \t80\n",
      "Accuracy: 0.0199999809265 \t81\n",
      "Accuracy: 0.0199999809265 \t82\n",
      "Accuracy: 0.0199999809265 \t83\n",
      "Accuracy: 0.0199999809265 \t84\n",
      "Accuracy: 0.0199999809265 \t85\n",
      "Accuracy: 0.0199999809265 \t86\n",
      "Accuracy: 0.0199999809265 \t87\n",
      "Accuracy: 0.0199999809265 \t88\n",
      "Accuracy: 0.0199999809265 \t89\n",
      "Accuracy: 0.0199999809265 \t90\n",
      "Accuracy: 0.0199999809265 \t91\n",
      "Accuracy: 0.0199999809265 \t92\n",
      "Accuracy: 0.0199999809265 \t93\n",
      "Accuracy: 0.0199999809265 \t94\n",
      "Accuracy: 0.0199999809265 \t95\n",
      "Accuracy: 0.0199999809265 \t96\n",
      "Accuracy: 0.0199999809265 \t97\n",
      "Accuracy: 0.0199999809265 \t98\n",
      "Accuracy: 0.0199999809265 \t99\n",
      "Accuracy: 0.0299999713898 \t0\n",
      "Accuracy: 0.0299999713898 \t1\n",
      "Accuracy: 0.0299999713898 \t2\n",
      "Accuracy: 0.0299999713898 \t3\n",
      "Accuracy: 0.0299999713898 \t4\n",
      "Accuracy: 0.0199999809265 \t5\n",
      "Accuracy: 0.0199999809265 \t6\n",
      "Accuracy: 0.0199999809265 \t7\n",
      "Accuracy: 0.0199999809265 \t8\n",
      "Accuracy: 0.0199999809265 \t9\n",
      "Accuracy: 0.0199999809265 \t10\n",
      "Accuracy: 0.0199999809265 \t11\n",
      "Accuracy: 0.0199999809265 \t12\n",
      "Accuracy: 0.0199999809265 \t13\n",
      "Accuracy: 0.0199999809265 \t14\n",
      "Accuracy: 0.0199999809265 \t15\n",
      "Accuracy: 0.0199999809265 \t16\n",
      "Accuracy: 0.0299999713898 \t17\n",
      "Accuracy: 0.0299999713898 \t18\n",
      "Accuracy: 0.0299999713898 \t19\n",
      "Accuracy: 0.0299999713898 \t20\n",
      "Accuracy: 0.0299999713898 \t21\n",
      "Accuracy: 0.0400000214577 \t22\n",
      "Accuracy: 0.0400000214577 \t23\n",
      "Accuracy: 0.0500000119209 \t24\n",
      "Accuracy: 0.0500000119209 \t25\n",
      "Accuracy: 0.0500000119209 \t26\n",
      "Accuracy: 0.0500000119209 \t27\n",
      "Accuracy: 0.0500000119209 \t28\n",
      "Accuracy: 0.0699999928474 \t29\n",
      "Accuracy: 0.0799999833107 \t30\n",
      "Accuracy: 0.0799999833107 \t31\n",
      "Accuracy: 0.0799999833107 \t32\n",
      "Accuracy: 0.0799999833107 \t33\n",
      "Accuracy: 0.0799999833107 \t34\n",
      "Accuracy: 0.0699999928474 \t35\n",
      "Accuracy: 0.0699999928474 \t36\n",
      "Accuracy: 0.0699999928474 \t37\n",
      "Accuracy: 0.0699999928474 \t38\n",
      "Accuracy: 0.0699999928474 \t39\n",
      "Accuracy: 0.0699999928474 \t40\n",
      "Accuracy: 0.0699999928474 \t41\n",
      "Accuracy: 0.0799999833107 \t42\n",
      "Accuracy: 0.0699999928474 \t43\n",
      "Accuracy: 0.0699999928474 \t44\n",
      "Accuracy: 0.0699999928474 \t45\n",
      "Accuracy: 0.0699999928474 \t46\n",
      "Accuracy: 0.0699999928474 \t47\n",
      "Accuracy: 0.0799999833107 \t48\n",
      "Accuracy: 0.0799999833107 \t49\n",
      "Accuracy: 0.089999973774 \t50\n",
      "Accuracy: 0.089999973774 \t51\n",
      "Accuracy: 0.089999973774 \t52\n",
      "Accuracy: 0.089999973774 \t53\n",
      "Accuracy: 0.089999973774 \t54\n",
      "Accuracy: 0.089999973774 \t55\n",
      "Accuracy: 0.089999973774 \t56\n",
      "Accuracy: 0.089999973774 \t57\n",
      "Accuracy: 0.089999973774 \t58\n",
      "Accuracy: 0.0799999833107 \t59\n",
      "Accuracy: 0.0799999833107 \t60\n",
      "Accuracy: 0.0799999833107 \t61\n",
      "Accuracy: 0.0799999833107 \t62\n",
      "Accuracy: 0.0799999833107 \t63\n",
      "Accuracy: 0.0799999833107 \t64\n",
      "Accuracy: 0.089999973774 \t65\n",
      "Accuracy: 0.089999973774 \t66\n",
      "Accuracy: 0.089999973774 \t67\n",
      "Accuracy: 0.089999973774 \t68\n",
      "Accuracy: 0.089999973774 \t69\n",
      "Accuracy: 0.089999973774 \t70\n",
      "Accuracy: 0.089999973774 \t71\n",
      "Accuracy: 0.089999973774 \t72\n",
      "Accuracy: 0.089999973774 \t73\n",
      "Accuracy: 0.089999973774 \t74\n",
      "Accuracy: 0.089999973774 \t75\n",
      "Accuracy: 0.089999973774 \t76\n",
      "Accuracy: 0.089999973774 \t77\n",
      "Accuracy: 0.089999973774 \t78\n",
      "Accuracy: 0.089999973774 \t79\n",
      "Accuracy: 0.089999973774 \t80\n",
      "Accuracy: 0.089999973774 \t81\n",
      "Accuracy: 0.100000023842 \t82\n",
      "Accuracy: 0.100000023842 \t83\n",
      "Accuracy: 0.110000014305 \t84\n",
      "Accuracy: 0.110000014305 \t85\n",
      "Accuracy: 0.120000004768 \t86\n",
      "Accuracy: 0.120000004768 \t87\n",
      "Accuracy: 0.120000004768 \t88\n",
      "Accuracy: 0.120000004768 \t89\n",
      "Accuracy: 0.110000014305 \t90\n",
      "Accuracy: 0.110000014305 \t91\n",
      "Accuracy: 0.110000014305 \t92\n",
      "Accuracy: 0.110000014305 \t93\n",
      "Accuracy: 0.110000014305 \t94\n",
      "Accuracy: 0.110000014305 \t95\n",
      "Accuracy: 0.110000014305 \t96\n",
      "Accuracy: 0.120000004768 \t97\n",
      "Accuracy: 0.110000014305 \t98\n",
      "Accuracy: 0.110000014305 \t99\n",
      "[(0.069999992847442627, 33), (0.019999980926513672, 36), (0.019999980926513672, 49), (0.12000000476837158, 86)]\n",
      "[4, 3]\n",
      "Final bead error: 0.0482000112534\n",
      "[True, True, True, True, True, True]\n",
      "Accuracy: 0.0199999809265 \t0\n",
      "Accuracy: 0.0199999809265 \t1\n",
      "Accuracy: 0.0199999809265 \t2\n",
      "Accuracy: 0.0199999809265 \t3\n",
      "Accuracy: 0.0199999809265 \t4\n",
      "Accuracy: 0.0199999809265 \t5\n",
      "Accuracy: 0.0199999809265 \t6\n",
      "Accuracy: 0.0199999809265 \t7\n",
      "Accuracy: 0.0199999809265 \t8\n",
      "Accuracy: 0.0199999809265 \t9\n",
      "Accuracy: 0.0199999809265 \t10\n",
      "Accuracy: 0.0299999713898 \t11\n",
      "Accuracy: 0.0299999713898 \t12\n",
      "Accuracy: 0.0299999713898 \t13\n",
      "Accuracy: 0.0299999713898 \t14\n",
      "Accuracy: 0.0299999713898 \t15\n",
      "Accuracy: 0.0299999713898 \t16\n",
      "Accuracy: 0.0299999713898 \t17\n",
      "Accuracy: 0.0299999713898 \t18\n",
      "Accuracy: 0.0299999713898 \t19\n",
      "Accuracy: 0.0299999713898 \t20\n",
      "Accuracy: 0.0400000214577 \t21\n",
      "Accuracy: 0.0400000214577 \t22\n",
      "Accuracy: 0.0400000214577 \t23\n",
      "Accuracy: 0.0400000214577 \t24\n",
      "Accuracy: 0.0299999713898 \t25\n",
      "Accuracy: 0.0299999713898 \t26\n",
      "Accuracy: 0.0299999713898 \t27\n",
      "Accuracy: 0.0299999713898 \t28\n",
      "Accuracy: 0.0299999713898 \t29\n",
      "Accuracy: 0.0299999713898 \t30\n",
      "Accuracy: 0.0299999713898 \t31\n",
      "Accuracy: 0.0299999713898 \t32\n",
      "Accuracy: 0.0500000119209 \t33\n",
      "Accuracy: 0.0500000119209 \t34\n",
      "Accuracy: 0.0400000214577 \t35\n",
      "Accuracy: 0.0400000214577 \t36\n",
      "Accuracy: 0.0400000214577 \t37\n",
      "Accuracy: 0.0400000214577 \t38\n",
      "Accuracy: 0.0400000214577 \t39\n",
      "Accuracy: 0.0400000214577 \t40\n",
      "Accuracy: 0.0400000214577 \t41\n",
      "Accuracy: 0.0400000214577 \t42\n",
      "Accuracy: 0.0400000214577 \t43\n",
      "Accuracy: 0.0400000214577 \t44\n",
      "Accuracy: 0.0400000214577 \t45\n",
      "Accuracy: 0.0400000214577 \t46\n",
      "Accuracy: 0.0400000214577 \t47\n",
      "Accuracy: 0.0400000214577 \t48\n",
      "Accuracy: 0.0400000214577 \t49\n",
      "Accuracy: 0.0400000214577 \t50\n",
      "Accuracy: 0.0400000214577 \t51\n",
      "Accuracy: 0.0400000214577 \t52\n",
      "Accuracy: 0.0400000214577 \t53\n",
      "Accuracy: 0.0299999713898 \t54\n",
      "Accuracy: 0.0299999713898 \t55\n",
      "Accuracy: 0.0299999713898 \t56\n",
      "Accuracy: 0.0299999713898 \t57\n",
      "Accuracy: 0.0299999713898 \t58\n",
      "Accuracy: 0.0299999713898 \t59\n",
      "Accuracy: 0.0299999713898 \t60\n",
      "Accuracy: 0.0299999713898 \t61\n",
      "Accuracy: 0.0299999713898 \t62\n",
      "Accuracy: 0.0299999713898 \t63\n",
      "Accuracy: 0.0299999713898 \t64\n",
      "Accuracy: 0.0299999713898 \t65\n",
      "Accuracy: 0.0299999713898 \t66\n",
      "Accuracy: 0.0299999713898 \t67\n",
      "Accuracy: 0.0299999713898 \t68\n",
      "Accuracy: 0.0299999713898 \t69\n",
      "Accuracy: 0.0299999713898 \t70\n",
      "Accuracy: 0.0299999713898 \t71\n",
      "Accuracy: 0.0299999713898 \t72\n",
      "Accuracy: 0.0199999809265 \t73\n",
      "Accuracy: 0.0199999809265 \t74\n",
      "Accuracy: 0.0199999809265 \t75\n",
      "Accuracy: 0.0199999809265 \t76\n",
      "Accuracy: 0.0199999809265 \t77\n",
      "Accuracy: 0.0199999809265 \t78\n",
      "Accuracy: 0.0199999809265 \t79\n",
      "Accuracy: 0.0199999809265 \t80\n",
      "Accuracy: 0.0199999809265 \t81\n",
      "Accuracy: 0.0199999809265 \t82\n",
      "Accuracy: 0.00999999046326 \t83\n",
      "Accuracy: 0.00999999046326 \t84\n",
      "Accuracy: 0.00999999046326 \t85\n",
      "Accuracy: 0.0 \t86\n",
      "Accuracy: 0.0 \t87\n",
      "Accuracy: 0.0 \t88\n",
      "Accuracy: 0.0 \t89\n",
      "Accuracy: 0.0 \t90\n",
      "Accuracy: 0.0 \t91\n",
      "Accuracy: 0.0 \t92\n",
      "Accuracy: 0.0 \t93\n",
      "Accuracy: 0.0 \t94\n",
      "Accuracy: 0.0 \t95\n",
      "Accuracy: 0.0 \t96\n",
      "Accuracy: 0.0 \t97\n",
      "Accuracy: 0.0 \t98\n",
      "Accuracy: 0.0 \t99\n",
      "Accuracy: 0.0199999809265 \t0\n",
      "Accuracy: 0.0299999713898 \t1\n",
      "Accuracy: 0.0299999713898 \t2\n",
      "Accuracy: 0.0299999713898 \t3\n",
      "Accuracy: 0.0299999713898 \t4\n",
      "Accuracy: 0.0299999713898 \t5\n",
      "Accuracy: 0.0299999713898 \t6\n",
      "Accuracy: 0.0299999713898 \t7\n",
      "Accuracy: 0.0299999713898 \t8\n",
      "Accuracy: 0.0299999713898 \t9\n",
      "Accuracy: 0.0299999713898 \t10\n",
      "Accuracy: 0.0299999713898 \t11\n",
      "Accuracy: 0.0299999713898 \t12\n",
      "Accuracy: 0.0299999713898 \t13\n",
      "Accuracy: 0.0299999713898 \t14\n",
      "Accuracy: 0.0299999713898 \t15\n",
      "Accuracy: 0.0299999713898 \t16\n",
      "Accuracy: 0.0299999713898 \t17\n",
      "Accuracy: 0.0299999713898 \t18\n",
      "Accuracy: 0.0299999713898 \t19\n",
      "Accuracy: 0.0299999713898 \t20\n",
      "Accuracy: 0.0299999713898 \t21\n",
      "Accuracy: 0.0299999713898 \t22\n",
      "Accuracy: 0.0299999713898 \t23\n",
      "Accuracy: 0.0299999713898 \t24\n",
      "Accuracy: 0.0299999713898 \t25\n",
      "Accuracy: 0.0299999713898 \t26\n",
      "Accuracy: 0.0299999713898 \t27\n",
      "Accuracy: 0.0299999713898 \t28\n",
      "Accuracy: 0.0299999713898 \t29\n",
      "Accuracy: 0.0299999713898 \t30\n",
      "Accuracy: 0.0299999713898 \t31\n",
      "Accuracy: 0.0299999713898 \t32\n",
      "Accuracy: 0.0299999713898 \t33\n",
      "Accuracy: 0.0299999713898 \t34\n",
      "Accuracy: 0.0299999713898 \t35\n",
      "Accuracy: 0.0299999713898 \t36\n",
      "Accuracy: 0.0299999713898 \t37\n",
      "Accuracy: 0.0299999713898 \t38\n",
      "Accuracy: 0.0299999713898 \t39\n",
      "Accuracy: 0.0299999713898 \t40\n",
      "Accuracy: 0.0299999713898 \t41\n",
      "Accuracy: 0.0400000214577 \t42\n",
      "Accuracy: 0.0400000214577 \t43\n",
      "Accuracy: 0.0400000214577 \t44\n",
      "Accuracy: 0.0400000214577 \t45\n",
      "Accuracy: 0.0500000119209 \t46\n",
      "Accuracy: 0.0500000119209 \t47\n",
      "Accuracy: 0.0500000119209 \t48\n",
      "Accuracy: 0.0500000119209 \t49\n",
      "Accuracy: 0.0500000119209 \t50\n",
      "Accuracy: 0.0500000119209 \t51\n",
      "Accuracy: 0.0500000119209 \t52\n",
      "Accuracy: 0.0500000119209 \t53\n",
      "Accuracy: 0.0600000023842 \t54\n",
      "Accuracy: 0.0600000023842 \t55\n",
      "Accuracy: 0.0699999928474 \t56\n",
      "Accuracy: 0.0699999928474 \t57\n",
      "Accuracy: 0.0699999928474 \t58\n",
      "Accuracy: 0.0699999928474 \t59\n",
      "Accuracy: 0.0699999928474 \t60\n",
      "Accuracy: 0.0699999928474 \t61\n",
      "Accuracy: 0.0699999928474 \t62\n",
      "Accuracy: 0.0699999928474 \t63\n",
      "Accuracy: 0.0699999928474 \t64\n",
      "Accuracy: 0.0699999928474 \t65\n",
      "Accuracy: 0.0699999928474 \t66\n",
      "Accuracy: 0.0699999928474 \t67\n",
      "Accuracy: 0.0699999928474 \t68\n",
      "Accuracy: 0.0699999928474 \t69\n",
      "Accuracy: 0.0699999928474 \t70\n",
      "Accuracy: 0.0699999928474 \t71\n",
      "Accuracy: 0.0699999928474 \t72\n",
      "Accuracy: 0.0699999928474 \t73\n",
      "Accuracy: 0.0699999928474 \t74\n",
      "Accuracy: 0.0699999928474 \t75\n",
      "Accuracy: 0.0699999928474 \t76\n",
      "Accuracy: 0.0699999928474 \t77\n",
      "Accuracy: 0.0699999928474 \t78\n",
      "Accuracy: 0.0699999928474 \t79\n",
      "Accuracy: 0.0699999928474 \t80\n",
      "Accuracy: 0.0699999928474 \t81\n",
      "Accuracy: 0.0699999928474 \t82\n",
      "Accuracy: 0.0699999928474 \t83\n",
      "Accuracy: 0.0699999928474 \t84\n",
      "Accuracy: 0.0699999928474 \t85\n",
      "Accuracy: 0.0699999928474 \t86\n",
      "Accuracy: 0.0699999928474 \t87\n",
      "Accuracy: 0.0699999928474 \t88\n",
      "Accuracy: 0.0699999928474 \t89\n",
      "Accuracy: 0.0699999928474 \t90\n",
      "Accuracy: 0.0699999928474 \t91\n",
      "Accuracy: 0.0699999928474 \t92\n",
      "Accuracy: 0.0699999928474 \t93\n",
      "Accuracy: 0.0699999928474 \t94\n",
      "Accuracy: 0.0699999928474 \t95\n",
      "Accuracy: 0.0699999928474 \t96\n",
      "Accuracy: 0.0699999928474 \t97\n",
      "Accuracy: 0.0699999928474 \t98\n",
      "Accuracy: 0.0600000023842 \t99\n",
      "[(0.050000011920928955, 33), (0.069999992847442627, 56)]\n",
      "1\n",
      "2\n",
      "Thresh: 0.1\n",
      "Comps: 1\n",
      "***\n",
      "176.260862648\n",
      "3.33940654993\n"
     ]
    }
   ],
   "source": [
    "#Connected components search\n",
    "\n",
    "\n",
    "#Used for softening the training criteria.  There's some fuzz required due to the difference in \n",
    "#training error between test and training\n",
    "thresh_multiplier = 1.1\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "connecteddict = {}\n",
    "for i1 in xrange(len(models)):\n",
    "    connecteddict[i1] = 'not connected'\n",
    "\n",
    "\n",
    "for i1 in xrange(len(models)):\n",
    "    print i1\n",
    "    for i2 in xrange(len(models)):\n",
    "        \n",
    "        if i2 > i1 and ((connecteddict[i1] != connecteddict[i2]) or (connecteddict[i1] == 'not connected' or connecteddict[i2] == 'not connected')) :\n",
    "            #print \"slow1?\"\n",
    "            #print i1,i2\n",
    "            #print models[0]\n",
    "            #print models[1]\n",
    "            #print models[0].params\n",
    "            #print models[1].params\n",
    "            test = WeightString(models[i1].params[0],models[i1].params[1],models[i2].params[0],models[i2].params[1],1,1)\n",
    "\n",
    "            training_threshold = thresh\n",
    "\n",
    "            depth = 0\n",
    "            d_max = 10\n",
    "\n",
    "            #Check error between beads\n",
    "            #Alg: for each bead at depth i, SGD until converged.\n",
    "            #For beads with max error along path too large, add another bead between them, repeat\n",
    "\n",
    "            \n",
    "            #Keeps track of which indices to check the interpbeaderror between\n",
    "            newindices = [0,1]\n",
    "            \n",
    "            while (depth < d_max):\n",
    "                print newindices\n",
    "                #print \"slow2?\"\n",
    "                #X, y = GenTest(X,y)\n",
    "                counter = 0\n",
    "\n",
    "                for i,c in enumerate(test.ConvergedList):\n",
    "                    if c == False:\n",
    "                        #print \"slow3?\"\n",
    "                        error = test.SGDBead(i, .5*training_threshold, 20)\n",
    "                        #print \"slow4?\"\n",
    "                            #if counter%5000==0:\n",
    "                            #    print counter\n",
    "                            #    print error\n",
    "                        test.ConvergedList[i] = True\n",
    "\n",
    "                print test.ConvergedList\n",
    "\n",
    "                interperrors = []\n",
    "                interp_bead_indices = []\n",
    "                for b in xrange(len(test.AllBeads)-1):\n",
    "                    if b in newindices:\n",
    "                        e = InterpBeadError(test.AllBeads[b][0],test.AllBeads[b][1], test.AllBeads[b+1][0], test.AllBeads[b+1][1])\n",
    "\n",
    "                        interperrors.append(e)\n",
    "                        interp_bead_indices.append(b)\n",
    "                print interperrors\n",
    "\n",
    "                if max([ee[0] for ee in interperrors]) < thresh_multiplier*training_threshold:\n",
    "                    depth = 2*d_max\n",
    "                    #print test.ConvergedList\n",
    "                    #print test.SpringNorm(2)\n",
    "                    #print \"Done!\"\n",
    "\n",
    "                else:\n",
    "                    del newindices[:]\n",
    "                    #Interperrors stores the maximum error on the path between beads\n",
    "                    #shift index to account for added beads\n",
    "                    shift = 0\n",
    "                    for i, ie in enumerate(interperrors):\n",
    "                        if ie[0] > thresh_multiplier*training_threshold:\n",
    "                            k = interp_bead_indices[i]\n",
    "                            \n",
    "                            ws,bs = model_interpolate(test.AllBeads[k+shift][0],test.AllBeads[k+shift][1],\\\n",
    "                                                      test.AllBeads[k+shift+1][0],test.AllBeads[k+shift+1][1],\\\n",
    "                                                      ie[1]/100.)\n",
    "                            \n",
    "                            test.AllBeads.insert(k+shift+1,[ws,bs])\n",
    "                            test.ConvergedList.insert(k+shift+1, False)\n",
    "                            newindices.append(k+shift+1)\n",
    "                            newindices.append(k+shift)\n",
    "                            shift+=1\n",
    "                            #print test.ConvergedList\n",
    "                            #print test.SpringNorm(2)\n",
    "\n",
    "\n",
    "                    #print d_max\n",
    "                    depth += 1\n",
    "            if depth == 2*d_max:\n",
    "                results.append([i1,i2,test.SpringNorm(2),\"Connected\"])\n",
    "                if connecteddict[i1] == 'not connected' and connecteddict[i2] == 'not connected':\n",
    "                    connecteddict[i1] = i1\n",
    "                    connecteddict[i2] = i1\n",
    "\n",
    "                if connecteddict[i1] == 'not connected':\n",
    "                    connecteddict[i1] = connecteddict[i2]\n",
    "                else:\n",
    "                    if connecteddict[i2] == 'not connected':\n",
    "                        connecteddict[i2] = connecteddict[i1]\n",
    "                    else:\n",
    "                        if connecteddict[i1] != 'not connected' and connecteddict[i2] != 'not connected':\n",
    "                            hold = connecteddict[i2]\n",
    "                            connecteddict[i2] = connecteddict[i1]\n",
    "                            for h in xrange(len(models)):\n",
    "                                if connecteddict[h] == hold:\n",
    "                                    connecteddict[h] = connecteddict[i1]\n",
    "                    \n",
    "            else:\n",
    "                results.append([i1,i2,test.SpringNorm(2),\"Disconnected\"])\n",
    "            #print results[-1]\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\n",
    "uniquecomps = []\n",
    "totalcomps = 0\n",
    "for i in xrange(len(models)):\n",
    "    if not (connecteddict[i] in uniquecomps):\n",
    "        uniquecomps.append(connecteddict[i])\n",
    "    \n",
    "    if connecteddict[i] == 'not connected':\n",
    "        totalcomps += 1\n",
    "        \n",
    "    #print i,connecteddict[i]\n",
    "\n",
    "notconoffset = 0\n",
    "\n",
    "if 'not connected' in uniquecomps:\n",
    "    notconoffset = -1\n",
    "    \n",
    "print \"Thresh: \" + str(thresh)\n",
    "print \"Comps: \" + str(len(uniquecomps) + notconoffset + totalcomps)\n",
    "\n",
    "\n",
    "\n",
    "#for i in xrange(len(synapses)):\n",
    "#    print connecteddict[i]\n",
    "\n",
    "connsum = []\n",
    "for r in results:\n",
    "    if r[3] == \"Connected\":\n",
    "        connsum.append(r[2])\n",
    "        #print r[2]\n",
    "        \n",
    "print \"***\"\n",
    "print np.average(connsum)\n",
    "print np.std(connsum)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.multilayer_perceptron instance at 0x7fc3f3ce0518>,\n",
       " <__main__.multilayer_perceptron instance at 0x7fc3f3ce00e0>,\n",
       " <__main__.multilayer_perceptron instance at 0x7fc3f366cb00>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.AllBeads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.100000023842 \t0 0.813 -0.818951\n",
      "Accuracy: 0.100000023842 \t1 0.811995 -0.815392\n",
      "Accuracy: 0.100000023842 \t2 0.81099 -0.811833\n",
      "Accuracy: 0.100000023842 \t3 0.809985 -0.808274\n",
      "Accuracy: 0.100000023842 \t4 0.808979 -0.804715\n",
      "Accuracy: 0.089999973774 \t5 0.807974 -0.801156\n",
      "Accuracy: 0.089999973774 \t6 0.806969 -0.797597\n",
      "Accuracy: 0.089999973774 \t7 0.805964 -0.794038\n",
      "Accuracy: 0.089999973774 \t8 0.804959 -0.790479\n",
      "Accuracy: 0.089999973774 \t9 0.803954 -0.78692\n",
      "Accuracy: 0.089999973774 \t10 0.802949 -0.783361\n",
      "Accuracy: 0.089999973774 \t11 0.801944 -0.779802\n",
      "Accuracy: 0.089999973774 \t12 0.800939 -0.776243\n",
      "Accuracy: 0.089999973774 \t13 0.799934 -0.772684\n",
      "Accuracy: 0.089999973774 \t14 0.798929 -0.769125\n",
      "Accuracy: 0.089999973774 \t15 0.797924 -0.765566\n",
      "Accuracy: 0.089999973774 \t16 0.796918 -0.762007\n",
      "Accuracy: 0.089999973774 \t17 0.795913 -0.758448\n",
      "Accuracy: 0.089999973774 \t18 0.794908 -0.754889\n",
      "Accuracy: 0.089999973774 \t19 0.793903 -0.75133\n",
      "Accuracy: 0.089999973774 \t20 0.792898 -0.747771\n",
      "Accuracy: 0.089999973774 \t21 0.791893 -0.744212\n",
      "Accuracy: 0.089999973774 \t22 0.790888 -0.740653\n",
      "Accuracy: 0.089999973774 \t23 0.789883 -0.737094\n",
      "Accuracy: 0.089999973774 \t24 0.788878 -0.733535\n",
      "Accuracy: 0.089999973774 \t25 0.787873 -0.729976\n",
      "Accuracy: 0.0799999833107 \t26 0.786868 -0.726417\n",
      "Accuracy: 0.0799999833107 \t27 0.785862 -0.722858\n",
      "Accuracy: 0.0699999928474 \t28 0.784857 -0.719299\n",
      "Accuracy: 0.0699999928474 \t29 0.783852 -0.71574\n",
      "Accuracy: 0.0699999928474 \t30 0.782847 -0.712181\n",
      "Accuracy: 0.0699999928474 \t31 0.781842 -0.708622\n",
      "Accuracy: 0.0699999928474 \t32 0.780837 -0.705063\n",
      "Accuracy: 0.0699999928474 \t33 0.779832 -0.701504\n",
      "Accuracy: 0.0699999928474 \t34 0.778827 -0.697945\n",
      "Accuracy: 0.0699999928474 \t35 0.777822 -0.694386\n",
      "Accuracy: 0.0699999928474 \t36 0.776817 -0.690827\n",
      "Accuracy: 0.0699999928474 \t37 0.775812 -0.687268\n",
      "Accuracy: 0.0699999928474 \t38 0.774806 -0.683709\n",
      "Accuracy: 0.0699999928474 \t39 0.773801 -0.68015\n",
      "Accuracy: 0.0699999928474 \t40 0.772796 -0.676591\n",
      "Accuracy: 0.0699999928474 \t41 0.771791 -0.673032\n",
      "Accuracy: 0.0699999928474 \t42 0.770786 -0.669473\n",
      "Accuracy: 0.0600000023842 \t43 0.769781 -0.665914\n",
      "Accuracy: 0.0600000023842 \t44 0.768776 -0.662355\n",
      "Accuracy: 0.0600000023842 \t45 0.767771 -0.658796\n",
      "Accuracy: 0.0600000023842 \t46 0.766766 -0.655237\n",
      "Accuracy: 0.0500000119209 \t47 0.765761 -0.651678\n",
      "Accuracy: 0.0500000119209 \t48 0.764756 -0.648119\n",
      "Accuracy: 0.0500000119209 \t49 0.763751 -0.64456\n",
      "Accuracy: 0.0400000214577 \t50 0.762745 -0.641001\n",
      "Accuracy: 0.0400000214577 \t51 0.76174 -0.637442\n",
      "Accuracy: 0.0400000214577 \t52 0.760735 -0.633883\n",
      "Accuracy: 0.0400000214577 \t53 0.75973 -0.630324\n",
      "Accuracy: 0.0400000214577 \t54 0.758725 -0.626765\n",
      "Accuracy: 0.0400000214577 \t55 0.75772 -0.623206\n",
      "Accuracy: 0.0400000214577 \t56 0.756715 -0.619647\n",
      "Accuracy: 0.0400000214577 \t57 0.75571 -0.616088\n",
      "Accuracy: 0.0299999713898 \t58 0.754705 -0.612529\n",
      "Accuracy: 0.0299999713898 \t59 0.7537 -0.60897\n",
      "Accuracy: 0.0199999809265 \t60 0.752695 -0.605411\n",
      "Accuracy: 0.0199999809265 \t61 0.751689 -0.601852\n",
      "Accuracy: 0.0199999809265 \t62 0.750684 -0.598293\n",
      "Accuracy: 0.0199999809265 \t63 0.749679 -0.594734\n",
      "Accuracy: 0.0199999809265 \t64 0.748674 -0.591175\n",
      "Accuracy: 0.0199999809265 \t65 0.747669 -0.587616\n",
      "Accuracy: 0.0199999809265 \t66 0.746664 -0.584057\n",
      "Accuracy: 0.0199999809265 \t67 0.745659 -0.580498\n",
      "Accuracy: 0.0199999809265 \t68 0.744654 -0.576939\n",
      "Accuracy: 0.0199999809265 \t69 0.743649 -0.57338\n",
      "Accuracy: 0.0199999809265 \t70 0.742644 -0.569821\n",
      "Accuracy: 0.0199999809265 \t71 0.741639 -0.566262\n",
      "Accuracy: 0.0199999809265 \t72 0.740634 -0.562703\n",
      "Accuracy: 0.0199999809265 \t73 0.739628 -0.559144\n",
      "Accuracy: 0.0199999809265 \t74 0.738623 -0.555585\n",
      "Accuracy: 0.0199999809265 \t75 0.737618 -0.552026\n",
      "Accuracy: 0.0199999809265 \t76 0.736613 -0.548467\n",
      "Accuracy: 0.0199999809265 \t77 0.735608 -0.544908\n",
      "Accuracy: 0.0199999809265 \t78 0.734603 -0.541349\n",
      "Accuracy: 0.0199999809265 \t79 0.733598 -0.53779\n",
      "Accuracy: 0.0199999809265 \t80 0.732593 -0.534231\n",
      "Accuracy: 0.0199999809265 \t81 0.731588 -0.530672\n",
      "Accuracy: 0.0199999809265 \t82 0.730583 -0.527113\n",
      "Accuracy: 0.0199999809265 \t83 0.729578 -0.523554\n",
      "Accuracy: 0.0199999809265 \t84 0.728573 -0.519995\n",
      "Accuracy: 0.0199999809265 \t85 0.727567 -0.516436\n",
      "Accuracy: 0.0199999809265 \t86 0.726562 -0.512877\n",
      "Accuracy: 0.00999999046326 \t87 0.725557 -0.509318\n",
      "Accuracy: 0.00999999046326 \t88 0.724552 -0.505759\n",
      "Accuracy: 0.00999999046326 \t89 0.723547 -0.5022\n",
      "Accuracy: 0.0 \t90 0.722542 -0.498641\n",
      "Accuracy: 0.0 \t91 0.721537 -0.495082\n",
      "Accuracy: 0.0 \t92 0.720532 -0.491523\n",
      "Accuracy: 0.0 \t93 0.719527 -0.487964\n",
      "Accuracy: 0.0 \t94 0.718522 -0.484405\n",
      "Accuracy: 0.0 \t95 0.717517 -0.480846\n",
      "Accuracy: 0.0 \t96 0.716511 -0.477287\n",
      "Accuracy: 0.0 \t97 0.715506 -0.473728\n",
      "Accuracy: 0.0 \t98 0.714501 -0.470169\n",
      "Accuracy: 0.0 \t99 0.713496 -0.46661\n",
      "Accuracy: 0.0199999809265 \t0 0.712491 -0.463051\n",
      "Accuracy: 0.0199999809265 \t1 0.711263 -0.458701\n",
      "Accuracy: 0.0199999809265 \t2 0.710034 -0.454351\n",
      "Accuracy: 0.0199999809265 \t3 0.708806 -0.450001\n",
      "Accuracy: 0.0199999809265 \t4 0.707577 -0.445651\n",
      "Accuracy: 0.0199999809265 \t5 0.706349 -0.441301\n",
      "Accuracy: 0.0199999809265 \t6 0.705121 -0.436952\n",
      "Accuracy: 0.0199999809265 \t7 0.703892 -0.432602\n",
      "Accuracy: 0.0199999809265 \t8 0.702664 -0.428252\n",
      "Accuracy: 0.0199999809265 \t9 0.701435 -0.423902\n",
      "Accuracy: 0.0199999809265 \t10 0.700207 -0.419552\n",
      "Accuracy: 0.0199999809265 \t11 0.698978 -0.415202\n",
      "Accuracy: 0.0199999809265 \t12 0.69775 -0.410852\n",
      "Accuracy: 0.00999999046326 \t13 0.696521 -0.406502\n",
      "Accuracy: 0.00999999046326 \t14 0.695293 -0.402152\n",
      "Accuracy: 0.0199999809265 \t15 0.694065 -0.397803\n",
      "Accuracy: 0.0199999809265 \t16 0.692836 -0.393453\n",
      "Accuracy: 0.0199999809265 \t17 0.691608 -0.389103\n",
      "Accuracy: 0.0299999713898 \t18 0.690379 -0.384753\n",
      "Accuracy: 0.0299999713898 \t19 0.689151 -0.380403\n",
      "Accuracy: 0.0299999713898 \t20 0.687922 -0.376053\n",
      "Accuracy: 0.0299999713898 \t21 0.686694 -0.371703\n",
      "Accuracy: 0.0299999713898 \t22 0.685466 -0.367353\n",
      "Accuracy: 0.0299999713898 \t23 0.684237 -0.363003\n",
      "Accuracy: 0.0299999713898 \t24 0.683009 -0.358653\n",
      "Accuracy: 0.0299999713898 \t25 0.68178 -0.354304\n",
      "Accuracy: 0.0299999713898 \t26 0.680552 -0.349954\n",
      "Accuracy: 0.0299999713898 \t27 0.679323 -0.345604\n",
      "Accuracy: 0.0299999713898 \t28 0.678095 -0.341254\n",
      "Accuracy: 0.0299999713898 \t29 0.676866 -0.336904\n",
      "Accuracy: 0.0299999713898 \t30 0.675638 -0.332554\n",
      "Accuracy: 0.0299999713898 \t31 0.67441 -0.328204\n",
      "Accuracy: 0.0299999713898 \t32 0.673181 -0.323854\n",
      "Accuracy: 0.0299999713898 \t33 0.671953 -0.319504\n",
      "Accuracy: 0.0299999713898 \t34 0.670724 -0.315155\n",
      "Accuracy: 0.0299999713898 \t35 0.669496 -0.310805\n",
      "Accuracy: 0.0299999713898 \t36 0.668267 -0.306455\n",
      "Accuracy: 0.0299999713898 \t37 0.667039 -0.302105\n",
      "Accuracy: 0.0299999713898 \t38 0.66581 -0.297755\n",
      "Accuracy: 0.0299999713898 \t39 0.664582 -0.293405\n",
      "Accuracy: 0.0299999713898 \t40 0.663354 -0.289055\n",
      "Accuracy: 0.0299999713898 \t41 0.662125 -0.284705\n",
      "Accuracy: 0.0199999809265 \t42 0.660897 -0.280355\n",
      "Accuracy: 0.0199999809265 \t43 0.659668 -0.276006\n",
      "Accuracy: 0.0199999809265 \t44 0.65844 -0.271656\n",
      "Accuracy: 0.0299999713898 \t45 0.657211 -0.267306\n",
      "Accuracy: 0.0299999713898 \t46 0.655983 -0.262956\n",
      "Accuracy: 0.0299999713898 \t47 0.654755 -0.258606\n",
      "Accuracy: 0.0299999713898 \t48 0.653526 -0.254256\n",
      "Accuracy: 0.0299999713898 \t49 0.652298 -0.249906\n",
      "Accuracy: 0.0299999713898 \t50 0.651069 -0.245556\n",
      "Accuracy: 0.0299999713898 \t51 0.649841 -0.241206\n",
      "Accuracy: 0.0299999713898 \t52 0.648612 -0.236856\n",
      "Accuracy: 0.0299999713898 \t53 0.647384 -0.232507\n",
      "Accuracy: 0.0299999713898 \t54 0.646155 -0.228157\n",
      "Accuracy: 0.0299999713898 \t55 0.644927 -0.223807\n",
      "Accuracy: 0.0299999713898 \t56 0.643699 -0.219457\n",
      "Accuracy: 0.0299999713898 \t57 0.64247 -0.215107\n",
      "Accuracy: 0.0299999713898 \t58 0.641242 -0.210757\n",
      "Accuracy: 0.0299999713898 \t59 0.640013 -0.206407\n",
      "Accuracy: 0.0299999713898 \t60 0.638785 -0.202057\n",
      "Accuracy: 0.0299999713898 \t61 0.637556 -0.197707\n",
      "Accuracy: 0.0299999713898 \t62 0.636328 -0.193358\n",
      "Accuracy: 0.0299999713898 \t63 0.6351 -0.189008\n",
      "Accuracy: 0.0299999713898 \t64 0.633871 -0.184658\n",
      "Accuracy: 0.0299999713898 \t65 0.632643 -0.180308\n",
      "Accuracy: 0.0299999713898 \t66 0.631414 -0.175958\n",
      "Accuracy: 0.0299999713898 \t67 0.630186 -0.171608\n",
      "Accuracy: 0.0299999713898 \t68 0.628957 -0.167258\n",
      "Accuracy: 0.0400000214577 \t69 0.627729 -0.162908\n",
      "Accuracy: 0.0400000214577 \t70 0.6265 -0.158558\n",
      "Accuracy: 0.0400000214577 \t71 0.625272 -0.154208\n",
      "Accuracy: 0.0400000214577 \t72 0.624044 -0.149859\n",
      "Accuracy: 0.0299999713898 \t73 0.622815 -0.145509\n",
      "Accuracy: 0.0299999713898 \t74 0.621587 -0.141159\n",
      "Accuracy: 0.0299999713898 \t75 0.620358 -0.136809\n",
      "Accuracy: 0.0299999713898 \t76 0.61913 -0.132459\n",
      "Accuracy: 0.0299999713898 \t77 0.617901 -0.128109\n",
      "Accuracy: 0.0299999713898 \t78 0.616673 -0.123759\n",
      "Accuracy: 0.0299999713898 \t79 0.615444 -0.119409\n",
      "Accuracy: 0.0299999713898 \t80 0.614216 -0.115059\n",
      "Accuracy: 0.0299999713898 \t81 0.612988 -0.11071\n",
      "Accuracy: 0.0299999713898 \t82 0.611759 -0.10636\n",
      "Accuracy: 0.0299999713898 \t83 0.610531 -0.10201\n",
      "Accuracy: 0.0299999713898 \t84 0.609302 -0.0976599\n",
      "Accuracy: 0.0299999713898 \t85 0.608074 -0.09331\n",
      "Accuracy: 0.0299999713898 \t86 0.606845 -0.0889601\n",
      "Accuracy: 0.0299999713898 \t87 0.605617 -0.0846102\n",
      "Accuracy: 0.0299999713898 \t88 0.604389 -0.0802603\n",
      "Accuracy: 0.0299999713898 \t89 0.60316 -0.0759104\n",
      "Accuracy: 0.0199999809265 \t90 0.601932 -0.0715605\n",
      "Accuracy: 0.0299999713898 \t91 0.600703 -0.0672106\n",
      "Accuracy: 0.0299999713898 \t92 0.599475 -0.0628607\n",
      "Accuracy: 0.0299999713898 \t93 0.598246 -0.0585108\n",
      "Accuracy: 0.0299999713898 \t94 0.597018 -0.0541609\n",
      "Accuracy: 0.0299999713898 \t95 0.595789 -0.049811\n",
      "Accuracy: 0.0299999713898 \t96 0.594561 -0.0454611\n",
      "Accuracy: 0.0299999713898 \t97 0.593333 -0.0411112\n",
      "Accuracy: 0.0299999713898 \t98 0.592104 -0.0367613\n",
      "Accuracy: 0.0299999713898 \t99 0.590876 -0.0324115\n",
      "Accuracy: 0.0199999809265 \t0 0.589647 -0.0280616\n",
      "Accuracy: 0.0199999809265 \t1 0.588888 -0.0253725\n",
      "Accuracy: 0.0199999809265 \t2 0.588129 -0.0226835\n",
      "Accuracy: 0.0199999809265 \t3 0.587369 -0.0199945\n",
      "Accuracy: 0.0199999809265 \t4 0.58661 -0.0173055\n",
      "Accuracy: 0.0199999809265 \t5 0.58585 -0.0146164\n",
      "Accuracy: 0.0199999809265 \t6 0.585091 -0.0119274\n",
      "Accuracy: 0.0199999809265 \t7 0.584332 -0.00923839\n",
      "Accuracy: 0.0199999809265 \t8 0.583572 -0.00654937\n",
      "Accuracy: 0.0199999809265 \t9 0.582813 -0.00386034\n",
      "Accuracy: 0.0199999809265 \t10 0.582053 -0.00117132\n",
      "Accuracy: 0.0199999809265 \t11 0.581294 0.00151771\n",
      "Accuracy: 0.0199999809265 \t12 0.580535 0.00420673\n",
      "Accuracy: 0.0199999809265 \t13 0.579775 0.00689575\n",
      "Accuracy: 0.0199999809265 \t14 0.579016 0.00958478\n",
      "Accuracy: 0.0199999809265 \t15 0.578256 0.0122738\n",
      "Accuracy: 0.0199999809265 \t16 0.577497 0.0149628\n",
      "Accuracy: 0.0199999809265 \t17 0.576738 0.0176519\n",
      "Accuracy: 0.0199999809265 \t18 0.575978 0.0203409\n",
      "Accuracy: 0.0199999809265 \t19 0.575219 0.0230299\n",
      "Accuracy: 0.0199999809265 \t20 0.574459 0.0257189\n",
      "Accuracy: 0.0199999809265 \t21 0.5737 0.028408\n",
      "Accuracy: 0.0199999809265 \t22 0.572941 0.031097\n",
      "Accuracy: 0.0199999809265 \t23 0.572181 0.033786\n",
      "Accuracy: 0.0199999809265 \t24 0.571422 0.036475\n",
      "Accuracy: 0.0199999809265 \t25 0.570662 0.0391641\n",
      "Accuracy: 0.0199999809265 \t26 0.569903 0.0418531\n",
      "Accuracy: 0.0199999809265 \t27 0.569144 0.0445421\n",
      "Accuracy: 0.0199999809265 \t28 0.568384 0.0472311\n",
      "Accuracy: 0.0199999809265 \t29 0.567625 0.0499202\n",
      "Accuracy: 0.0199999809265 \t30 0.566865 0.0526092\n",
      "Accuracy: 0.0199999809265 \t31 0.566106 0.0552982\n",
      "Accuracy: 0.0199999809265 \t32 0.565347 0.0579872\n",
      "Accuracy: 0.0199999809265 \t33 0.564587 0.0606763\n",
      "Accuracy: 0.0199999809265 \t34 0.563828 0.0633653\n",
      "Accuracy: 0.0199999809265 \t35 0.563068 0.0660543\n",
      "Accuracy: 0.00999999046326 \t36 0.562309 0.0687433\n",
      "Accuracy: 0.00999999046326 \t37 0.56155 0.0714324\n",
      "Accuracy: 0.00999999046326 \t38 0.56079 0.0741214\n",
      "Accuracy: 0.00999999046326 \t39 0.560031 0.0768104\n",
      "Accuracy: 0.00999999046326 \t40 0.559271 0.0794994\n",
      "Accuracy: 0.00999999046326 \t41 0.558512 0.0821885\n",
      "Accuracy: 0.00999999046326 \t42 0.557753 0.0848775\n",
      "Accuracy: 0.00999999046326 \t43 0.556993 0.0875665\n",
      "Accuracy: 0.00999999046326 \t44 0.556234 0.0902555\n",
      "Accuracy: 0.00999999046326 \t45 0.555474 0.0929446\n",
      "Accuracy: 0.00999999046326 \t46 0.554715 0.0956336\n",
      "Accuracy: 0.00999999046326 \t47 0.553956 0.0983226\n",
      "Accuracy: 0.00999999046326 \t48 0.553196 0.101012\n",
      "Accuracy: 0.00999999046326 \t49 0.552437 0.103701\n",
      "Accuracy: 0.00999999046326 \t50 0.551677 0.10639\n",
      "Accuracy: 0.00999999046326 \t51 0.550918 0.109079\n",
      "Accuracy: 0.0199999809265 \t52 0.550159 0.111768\n",
      "Accuracy: 0.0199999809265 \t53 0.549399 0.114457\n",
      "Accuracy: 0.0199999809265 \t54 0.54864 0.117146\n",
      "Accuracy: 0.0199999809265 \t55 0.54788 0.119835\n",
      "Accuracy: 0.0199999809265 \t56 0.547121 0.122524\n",
      "Accuracy: 0.0199999809265 \t57 0.546362 0.125213\n",
      "Accuracy: 0.0199999809265 \t58 0.545602 0.127902\n",
      "Accuracy: 0.0199999809265 \t59 0.544843 0.130591\n",
      "Accuracy: 0.0199999809265 \t60 0.544083 0.13328\n",
      "Accuracy: 0.0199999809265 \t61 0.543324 0.135969\n",
      "Accuracy: 0.0199999809265 \t62 0.542565 0.138658\n",
      "Accuracy: 0.0199999809265 \t63 0.541805 0.141347\n",
      "Accuracy: 0.0199999809265 \t64 0.541046 0.144036\n",
      "Accuracy: 0.0199999809265 \t65 0.540286 0.146725\n",
      "Accuracy: 0.0199999809265 \t66 0.539527 0.149414\n",
      "Accuracy: 0.00999999046326 \t67 0.538768 0.152103\n",
      "Accuracy: 0.00999999046326 \t68 0.538008 0.154792\n",
      "Accuracy: 0.00999999046326 \t69 0.537249 0.157481\n",
      "Accuracy: 0.00999999046326 \t70 0.536489 0.16017\n",
      "Accuracy: 0.00999999046326 \t71 0.53573 0.162859\n",
      "Accuracy: 0.0199999809265 \t72 0.534971 0.165548\n",
      "Accuracy: 0.0199999809265 \t73 0.534211 0.168237\n",
      "Accuracy: 0.0199999809265 \t74 0.533452 0.170926\n",
      "Accuracy: 0.0199999809265 \t75 0.532692 0.173615\n",
      "Accuracy: 0.0199999809265 \t76 0.531933 0.176304\n",
      "Accuracy: 0.0199999809265 \t77 0.531174 0.178993\n",
      "Accuracy: 0.0199999809265 \t78 0.530414 0.181682\n",
      "Accuracy: 0.0199999809265 \t79 0.529655 0.184371\n",
      "Accuracy: 0.0199999809265 \t80 0.528895 0.18706\n",
      "Accuracy: 0.0199999809265 \t81 0.528136 0.189749\n",
      "Accuracy: 0.0199999809265 \t82 0.527377 0.192438\n",
      "Accuracy: 0.0199999809265 \t83 0.526617 0.195128\n",
      "Accuracy: 0.0199999809265 \t84 0.525858 0.197817\n",
      "Accuracy: 0.0199999809265 \t85 0.525098 0.200506\n",
      "Accuracy: 0.0199999809265 \t86 0.524339 0.203195\n",
      "Accuracy: 0.0199999809265 \t87 0.52358 0.205884\n",
      "Accuracy: 0.0199999809265 \t88 0.52282 0.208573\n",
      "Accuracy: 0.0199999809265 \t89 0.522061 0.211262\n",
      "Accuracy: 0.0199999809265 \t90 0.521301 0.213951\n",
      "Accuracy: 0.0199999809265 \t91 0.520542 0.21664\n",
      "Accuracy: 0.0199999809265 \t92 0.519783 0.219329\n",
      "Accuracy: 0.0199999809265 \t93 0.519023 0.222018\n",
      "Accuracy: 0.0199999809265 \t94 0.518264 0.224707\n",
      "Accuracy: 0.00999999046326 \t95 0.517504 0.227396\n",
      "Accuracy: 0.0 \t96 0.516745 0.230085\n",
      "Accuracy: 0.0 \t97 0.515986 0.232774\n",
      "Accuracy: 0.0 \t98 0.515226 0.235463\n",
      "Accuracy: 0.0 \t99 0.514467 0.238152\n",
      "Accuracy: 0.0299999713898 \t0 0.513707 0.240841\n",
      "Accuracy: 0.0299999713898 \t1 0.51244 0.24533\n",
      "Accuracy: 0.0299999713898 \t2 0.511172 0.249819\n",
      "Accuracy: 0.0299999713898 \t3 0.509904 0.254308\n",
      "Accuracy: 0.0299999713898 \t4 0.508636 0.258797\n",
      "Accuracy: 0.0299999713898 \t5 0.507369 0.263286\n",
      "Accuracy: 0.0299999713898 \t6 0.506101 0.267775\n",
      "Accuracy: 0.0299999713898 \t7 0.504833 0.272265\n",
      "Accuracy: 0.0299999713898 \t8 0.503565 0.276754\n",
      "Accuracy: 0.0299999713898 \t9 0.502298 0.281243\n",
      "Accuracy: 0.0400000214577 \t10 0.50103 0.285732\n",
      "Accuracy: 0.0400000214577 \t11 0.499762 0.290221\n",
      "Accuracy: 0.0400000214577 \t12 0.498494 0.29471\n",
      "Accuracy: 0.0400000214577 \t13 0.497227 0.299199\n",
      "Accuracy: 0.0400000214577 \t14 0.495959 0.303688\n",
      "Accuracy: 0.0400000214577 \t15 0.494691 0.308177\n",
      "Accuracy: 0.0400000214577 \t16 0.493423 0.312666\n",
      "Accuracy: 0.0400000214577 \t17 0.492156 0.317155\n",
      "Accuracy: 0.0400000214577 \t18 0.490888 0.321645\n",
      "Accuracy: 0.0400000214577 \t19 0.48962 0.326134\n",
      "Accuracy: 0.0400000214577 \t20 0.488352 0.330623\n",
      "Accuracy: 0.0400000214577 \t21 0.487085 0.335112\n",
      "Accuracy: 0.0500000119209 \t22 0.485817 0.339601\n",
      "Accuracy: 0.0500000119209 \t23 0.484549 0.34409\n",
      "Accuracy: 0.0500000119209 \t24 0.483281 0.348579\n",
      "Accuracy: 0.0500000119209 \t25 0.482014 0.353068\n",
      "Accuracy: 0.0600000023842 \t26 0.480746 0.357557\n",
      "Accuracy: 0.0600000023842 \t27 0.479478 0.362046\n",
      "Accuracy: 0.0500000119209 \t28 0.47821 0.366535\n",
      "Accuracy: 0.0500000119209 \t29 0.476943 0.371025\n",
      "Accuracy: 0.0500000119209 \t30 0.475675 0.375514\n",
      "Accuracy: 0.0500000119209 \t31 0.474407 0.380003\n",
      "Accuracy: 0.0500000119209 \t32 0.473139 0.384492\n",
      "Accuracy: 0.0500000119209 \t33 0.471872 0.388981\n",
      "Accuracy: 0.0500000119209 \t34 0.470604 0.39347\n",
      "Accuracy: 0.0500000119209 \t35 0.469336 0.397959\n",
      "Accuracy: 0.0500000119209 \t36 0.468068 0.402448\n",
      "Accuracy: 0.0500000119209 \t37 0.466801 0.406937\n",
      "Accuracy: 0.0500000119209 \t38 0.465533 0.411426\n",
      "Accuracy: 0.0500000119209 \t39 0.464265 0.415915\n",
      "Accuracy: 0.0500000119209 \t40 0.462997 0.420405\n",
      "Accuracy: 0.0500000119209 \t41 0.46173 0.424894\n",
      "Accuracy: 0.0500000119209 \t42 0.460462 0.429383\n",
      "Accuracy: 0.0500000119209 \t43 0.459194 0.433872\n",
      "Accuracy: 0.0500000119209 \t44 0.457927 0.438361\n",
      "Accuracy: 0.0500000119209 \t45 0.456659 0.44285\n",
      "Accuracy: 0.0500000119209 \t46 0.455391 0.447339\n",
      "Accuracy: 0.0500000119209 \t47 0.454123 0.451828\n",
      "Accuracy: 0.0500000119209 \t48 0.452855 0.456317\n",
      "Accuracy: 0.0500000119209 \t49 0.451588 0.460806\n",
      "Accuracy: 0.0500000119209 \t50 0.45032 0.465295\n",
      "Accuracy: 0.0500000119209 \t51 0.449052 0.469785\n",
      "Accuracy: 0.0500000119209 \t52 0.447785 0.474274\n",
      "Accuracy: 0.0500000119209 \t53 0.446517 0.478763\n",
      "Accuracy: 0.0500000119209 \t54 0.445249 0.483252\n",
      "Accuracy: 0.0600000023842 \t55 0.443981 0.487741\n",
      "Accuracy: 0.0600000023842 \t56 0.442713 0.49223\n",
      "Accuracy: 0.0600000023842 \t57 0.441446 0.496719\n",
      "Accuracy: 0.0600000023842 \t58 0.440178 0.501208\n",
      "Accuracy: 0.0600000023842 \t59 0.43891 0.505697\n",
      "Accuracy: 0.0500000119209 \t60 0.437643 0.510186\n",
      "Accuracy: 0.0500000119209 \t61 0.436375 0.514675\n",
      "Accuracy: 0.0500000119209 \t62 0.435107 0.519165\n",
      "Accuracy: 0.0500000119209 \t63 0.433839 0.523654\n",
      "Accuracy: 0.0500000119209 \t64 0.432572 0.528143\n",
      "Accuracy: 0.0500000119209 \t65 0.431304 0.532632\n",
      "Accuracy: 0.0500000119209 \t66 0.430036 0.537121\n",
      "Accuracy: 0.0500000119209 \t67 0.428768 0.54161\n",
      "Accuracy: 0.0500000119209 \t68 0.427501 0.546099\n",
      "Accuracy: 0.0500000119209 \t69 0.426233 0.550588\n",
      "Accuracy: 0.0500000119209 \t70 0.424965 0.555077\n",
      "Accuracy: 0.0500000119209 \t71 0.423697 0.559566\n",
      "Accuracy: 0.0500000119209 \t72 0.42243 0.564055\n",
      "Accuracy: 0.0500000119209 \t73 0.421162 0.568545\n",
      "Accuracy: 0.0400000214577 \t74 0.419894 0.573034\n",
      "Accuracy: 0.0400000214577 \t75 0.418626 0.577523\n",
      "Accuracy: 0.0400000214577 \t76 0.417359 0.582012\n",
      "Accuracy: 0.0400000214577 \t77 0.416091 0.586501\n",
      "Accuracy: 0.0400000214577 \t78 0.414823 0.59099\n",
      "Accuracy: 0.0299999713898 \t79 0.413555 0.595479\n",
      "Accuracy: 0.0299999713898 \t80 0.412288 0.599968\n",
      "Accuracy: 0.0199999809265 \t81 0.41102 0.604457\n",
      "Accuracy: 0.0199999809265 \t82 0.409752 0.608946\n",
      "Accuracy: 0.0199999809265 \t83 0.408484 0.613435\n",
      "Accuracy: 0.0199999809265 \t84 0.407217 0.617925\n",
      "Accuracy: 0.0199999809265 \t85 0.405949 0.622414\n",
      "Accuracy: 0.00999999046326 \t86 0.404681 0.626903\n",
      "Accuracy: 0.00999999046326 \t87 0.403413 0.631392\n",
      "Accuracy: 0.00999999046326 \t88 0.402146 0.635881\n",
      "Accuracy: 0.00999999046326 \t89 0.400878 0.64037\n",
      "Accuracy: 0.00999999046326 \t90 0.39961 0.644859\n",
      "Accuracy: 0.00999999046326 \t91 0.398342 0.649348\n",
      "Accuracy: 0.00999999046326 \t92 0.397075 0.653837\n",
      "Accuracy: 0.00999999046326 \t93 0.395807 0.658326\n",
      "Accuracy: 0.00999999046326 \t94 0.394539 0.662815\n",
      "Accuracy: 0.00999999046326 \t95 0.393271 0.667305\n",
      "Accuracy: 0.00999999046326 \t96 0.392004 0.671794\n",
      "Accuracy: 0.00999999046326 \t97 0.390736 0.676283\n",
      "Accuracy: 0.00999999046326 \t98 0.389468 0.680772\n",
      "Accuracy: 0.0199999809265 \t99 0.3882 0.685261\n",
      "Accuracy: 0.0500000119209 \t0 0.386933 0.68975\n",
      "Accuracy: 0.0500000119209 \t1 0.386726 0.690481\n",
      "Accuracy: 0.0500000119209 \t2 0.38652 0.691212\n",
      "Accuracy: 0.0500000119209 \t3 0.386313 0.691942\n",
      "Accuracy: 0.0500000119209 \t4 0.386107 0.692673\n",
      "Accuracy: 0.0500000119209 \t5 0.385901 0.693404\n",
      "Accuracy: 0.0500000119209 \t6 0.385694 0.694135\n",
      "Accuracy: 0.0500000119209 \t7 0.385488 0.694865\n",
      "Accuracy: 0.0500000119209 \t8 0.385282 0.695596\n",
      "Accuracy: 0.0500000119209 \t9 0.385075 0.696327\n",
      "Accuracy: 0.0400000214577 \t10 0.384869 0.697058\n",
      "Accuracy: 0.0400000214577 \t11 0.384662 0.697789\n",
      "Accuracy: 0.0400000214577 \t12 0.384456 0.698519\n",
      "Accuracy: 0.0400000214577 \t13 0.38425 0.69925\n",
      "Accuracy: 0.0400000214577 \t14 0.384043 0.699981\n",
      "Accuracy: 0.0400000214577 \t15 0.383837 0.700712\n",
      "Accuracy: 0.0400000214577 \t16 0.383631 0.701442\n",
      "Accuracy: 0.0400000214577 \t17 0.383424 0.702173\n",
      "Accuracy: 0.0400000214577 \t18 0.383218 0.702904\n",
      "Accuracy: 0.0400000214577 \t19 0.383011 0.703635\n",
      "Accuracy: 0.0400000214577 \t20 0.382805 0.704366\n",
      "Accuracy: 0.0400000214577 \t21 0.382599 0.705096\n",
      "Accuracy: 0.0400000214577 \t22 0.382392 0.705827\n",
      "Accuracy: 0.0400000214577 \t23 0.382186 0.706558\n",
      "Accuracy: 0.0400000214577 \t24 0.381979 0.707289\n",
      "Accuracy: 0.0500000119209 \t25 0.381773 0.708019\n",
      "Accuracy: 0.0500000119209 \t26 0.381567 0.70875\n",
      "Accuracy: 0.0500000119209 \t27 0.38136 0.709481\n",
      "Accuracy: 0.0500000119209 \t28 0.381154 0.710212\n",
      "Accuracy: 0.0500000119209 \t29 0.380948 0.710943\n",
      "Accuracy: 0.0500000119209 \t30 0.380741 0.711673\n",
      "Accuracy: 0.0500000119209 \t31 0.380535 0.712404\n",
      "Accuracy: 0.0500000119209 \t32 0.380328 0.713135\n",
      "Accuracy: 0.0500000119209 \t33 0.380122 0.713866\n",
      "Accuracy: 0.0500000119209 \t34 0.379916 0.714597\n",
      "Accuracy: 0.0500000119209 \t35 0.379709 0.715327\n",
      "Accuracy: 0.0500000119209 \t36 0.379503 0.716058\n",
      "Accuracy: 0.0500000119209 \t37 0.379297 0.716789\n",
      "Accuracy: 0.0600000023842 \t38 0.37909 0.71752\n",
      "Accuracy: 0.0600000023842 \t39 0.378884 0.71825\n",
      "Accuracy: 0.0600000023842 \t40 0.378677 0.718981\n",
      "Accuracy: 0.0699999928474 \t41 0.378471 0.719712\n",
      "Accuracy: 0.0699999928474 \t42 0.378265 0.720443\n",
      "Accuracy: 0.0699999928474 \t43 0.378058 0.721174\n",
      "Accuracy: 0.0699999928474 \t44 0.377852 0.721904\n",
      "Accuracy: 0.0699999928474 \t45 0.377646 0.722635\n",
      "Accuracy: 0.0699999928474 \t46 0.377439 0.723366\n",
      "Accuracy: 0.0699999928474 \t47 0.377233 0.724097\n",
      "Accuracy: 0.0699999928474 \t48 0.377026 0.724828\n",
      "Accuracy: 0.0699999928474 \t49 0.37682 0.725558\n",
      "Accuracy: 0.0699999928474 \t50 0.376614 0.726289\n",
      "Accuracy: 0.0799999833107 \t51 0.376407 0.72702\n",
      "Accuracy: 0.0799999833107 \t52 0.376201 0.727751\n",
      "Accuracy: 0.0799999833107 \t53 0.375995 0.728481\n",
      "Accuracy: 0.0799999833107 \t54 0.375788 0.729212\n",
      "Accuracy: 0.0799999833107 \t55 0.375582 0.729943\n",
      "Accuracy: 0.0799999833107 \t56 0.375375 0.730674\n",
      "Accuracy: 0.0799999833107 \t57 0.375169 0.731405\n",
      "Accuracy: 0.0699999928474 \t58 0.374963 0.732135\n",
      "Accuracy: 0.0699999928474 \t59 0.374756 0.732866\n",
      "Accuracy: 0.0699999928474 \t60 0.37455 0.733597\n",
      "Accuracy: 0.0699999928474 \t61 0.374344 0.734328\n",
      "Accuracy: 0.0699999928474 \t62 0.374137 0.735058\n",
      "Accuracy: 0.0699999928474 \t63 0.373931 0.735789\n",
      "Accuracy: 0.0799999833107 \t64 0.373724 0.73652\n",
      "Accuracy: 0.0799999833107 \t65 0.373518 0.737251\n",
      "Accuracy: 0.0799999833107 \t66 0.373312 0.737982\n",
      "Accuracy: 0.0799999833107 \t67 0.373105 0.738712\n",
      "Accuracy: 0.0799999833107 \t68 0.372899 0.739443\n",
      "Accuracy: 0.089999973774 \t69 0.372692 0.740174\n",
      "Accuracy: 0.089999973774 \t70 0.372486 0.740905\n",
      "Accuracy: 0.089999973774 \t71 0.37228 0.741636\n",
      "Accuracy: 0.089999973774 \t72 0.372073 0.742366\n",
      "Accuracy: 0.089999973774 \t73 0.371867 0.743097\n",
      "Accuracy: 0.089999973774 \t74 0.371661 0.743828\n",
      "Accuracy: 0.089999973774 \t75 0.371454 0.744559\n",
      "Accuracy: 0.089999973774 \t76 0.371248 0.745289\n",
      "Accuracy: 0.089999973774 \t77 0.371041 0.74602\n",
      "Accuracy: 0.089999973774 \t78 0.370835 0.746751\n",
      "Accuracy: 0.089999973774 \t79 0.370629 0.747482\n",
      "Accuracy: 0.089999973774 \t80 0.370422 0.748213\n",
      "Accuracy: 0.089999973774 \t81 0.370216 0.748943\n",
      "Accuracy: 0.089999973774 \t82 0.37001 0.749674\n",
      "Accuracy: 0.089999973774 \t83 0.369803 0.750405\n",
      "Accuracy: 0.089999973774 \t84 0.369597 0.751136\n",
      "Accuracy: 0.089999973774 \t85 0.36939 0.751866\n",
      "Accuracy: 0.089999973774 \t86 0.369184 0.752597\n",
      "Accuracy: 0.089999973774 \t87 0.368978 0.753328\n",
      "Accuracy: 0.089999973774 \t88 0.368771 0.754059\n",
      "Accuracy: 0.089999973774 \t89 0.368565 0.75479\n",
      "Accuracy: 0.100000023842 \t90 0.368359 0.75552\n",
      "Accuracy: 0.110000014305 \t91 0.368152 0.756251\n",
      "Accuracy: 0.120000004768 \t92 0.367946 0.756982\n",
      "Accuracy: 0.120000004768 \t93 0.367739 0.757713\n",
      "Accuracy: 0.120000004768 \t94 0.367533 0.758443\n",
      "Accuracy: 0.120000004768 \t95 0.367327 0.759174\n",
      "Accuracy: 0.120000004768 \t96 0.36712 0.759905\n",
      "Accuracy: 0.120000004768 \t97 0.366914 0.760636\n",
      "Accuracy: 0.120000004768 \t98 0.366708 0.761367\n",
      "Accuracy: 0.120000004768 \t99 0.366501 0.762097\n"
     ]
    }
   ],
   "source": [
    "for b in xrange(len(test.AllBeads)-1):\n",
    "    e = InterpBeadError(test.AllBeads[b][0],test.AllBeads[b][1], test.AllBeads[b+1][0], test.AllBeads[b+1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
